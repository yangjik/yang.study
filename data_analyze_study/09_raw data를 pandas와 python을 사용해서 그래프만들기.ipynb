{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc09e98",
   "metadata": {},
   "source": [
    "### 데이터 시각화\n",
    "- 데이터 분석 결과를 쉽게 이해할 수 있도록 시각적으로 표현\n",
    "- 탐색적 데이터 분석, 데이터 처리, 데이터 예측 모든 경우, 결과를 알아보기 쉽게하기 위해 필수.\n",
    "- 참고 사이트 : https://app.flourish.studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb06b8c",
   "metadata": {},
   "source": [
    "#### 1. 데이터확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c994593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-04-01 21:58:49   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-04-01 21:58:49   \n",
       "2  51001.0   Accomack        Virginia             US  2020-04-01 21:58:49   \n",
       "3  16001.0        Ada           Idaho             US  2020-04-01 21:58:49   \n",
       "4  19001.0      Adair            Iowa             US  2020-04-01 21:58:49   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707          4       0          0       4   \n",
       "1  30.295065  -92.414197         47       1          0      46   \n",
       "2  37.767072  -75.632346          7       0          0       7   \n",
       "3  43.452658 -116.241552        195       3          0     192   \n",
       "4  41.330756  -94.471059          1       0          0       1   \n",
       "\n",
       "                    Combined_Key  \n",
       "0  Abbeville, South Carolina, US  \n",
       "1          Acadia, Louisiana, US  \n",
       "2         Accomack, Virginia, US  \n",
       "3                 Ada, Idaho, US  \n",
       "4                Adair, Iowa, US  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'ex_datafile/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "\n",
    "csv = pd.read_csv(file_path+'04-01-2020.csv',encoding='utf-8')\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0785184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T10:13:19</td>\n",
       "      <td>66907</td>\n",
       "      <td>2761</td>\n",
       "      <td>31536</td>\n",
       "      <td>30.9756</td>\n",
       "      <td>112.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2020-03-01T23:43:03</td>\n",
       "      <td>3736</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-03-01T23:23:02</td>\n",
       "      <td>1694</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1349</td>\n",
       "      <td>7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23.3417</td>\n",
       "      <td>113.4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1272</td>\n",
       "      <td>22</td>\n",
       "      <td>1198</td>\n",
       "      <td>33.8820</td>\n",
       "      <td>113.6140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region          Last Update  Confirmed  Deaths  \\\n",
       "0          Hubei  Mainland China  2020-03-01T10:13:19      66907    2761   \n",
       "1            NaN     South Korea  2020-03-01T23:43:03       3736      17   \n",
       "2            NaN           Italy  2020-03-01T23:23:02       1694      34   \n",
       "3      Guangdong  Mainland China  2020-03-01T14:13:18       1349       7   \n",
       "4          Henan  Mainland China  2020-03-01T14:13:18       1272      22   \n",
       "\n",
       "   Recovered  Latitude  Longitude  \n",
       "0      31536   30.9756   112.2707  \n",
       "1         30   36.0000   128.0000  \n",
       "2         83   43.0000    12.0000  \n",
       "3       1016   23.3417   113.4244  \n",
       "4       1198   33.8820   113.6140  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'ex_datafile/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "\n",
    "csv = pd.read_csv(file_path+'03-01-2020.csv',encoding='utf-8')\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfdfb5",
   "metadata": {},
   "source": [
    "위에 데일리 데이터를 확인해보면 컬럼명이 변경이 되었다.<br>그래서 데이터 가공이 필요함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d022463",
   "metadata": {},
   "source": [
    "#### 2. 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedd3729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China        1.0\n",
       "1        Beijing  Mainland China       14.0\n",
       "2      Chongqing  Mainland China        6.0\n",
       "3         Fujian  Mainland China        1.0\n",
       "4          Gansu  Mainland China        NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(file_path+'01-22-2020.csv',encoding='utf-8')\n",
    "try : \n",
    "    csv = csv[['Province_State', 'Country_Region', 'Confirmed']] # col 지정해서 데이터프레임 추출\n",
    "\n",
    "except:\n",
    "    csv = csv[['Province/State', 'Country/Region', 'Confirmed']] # 해당 csv 파일의 col확인 후 데이터프레임 추출\n",
    "    csv.columns = ['Province_State', 'Country_Region', 'Confirmed'] # 추출한 데이터프레임 col명 변경\n",
    "    \n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327be764",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Province_State  35 non-null     object \n",
      " 1   Country_Region  38 non-null     object \n",
      " 2   Confirmed       29 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2717f83",
   "metadata": {},
   "source": [
    "#### 3. 데이터 프레임 데이터 변환\n",
    "    - 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    - 특정 컬럼에 없는 데이터 삭제(NaN)\n",
    "    - 특정 컬럼의 데이터 타입 변경 ex) str -> int형변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a36517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(file_path+'01-22-2020.csv',encoding='utf-8')\n",
    "try : \n",
    "    csv = csv[['Province_State', 'Country_Region', 'Confirmed']] # col 지정해서 데이터프레임 추출\n",
    "\n",
    "except:\n",
    "    csv = csv[['Province/State', 'Country/Region', 'Confirmed']] # 해당 csv 파일의 col확인 후 데이터프레임 추출\n",
    "    csv.columns = ['Province_State', 'Country_Region', 'Confirmed'] # 추출한 데이터프레임 col명 변경\n",
    "\n",
    "csv = csv.dropna(subset=['Confirmed'])\n",
    "csv = csv.astype({'Confirmed' : 'int64'})\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f737a",
   "metadata": {},
   "source": [
    "#### 4. 국가 코드 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>AQ</td>\n",
       "      <td>ATA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>-71.94990</td>\n",
       "      <td>23.347000</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID iso2 iso3  code3  FIPS Admin2 Province_State Country_Region       Lat  \\\n",
       "0    4   AF  AFG    4.0   NaN    NaN            NaN    Afghanistan  33.93911   \n",
       "1    8   AL  ALB    8.0   NaN    NaN            NaN        Albania  41.15330   \n",
       "2   10   AQ  ATA   10.0   NaN    NaN            NaN     Antarctica -71.94990   \n",
       "3   12   DZ  DZA   12.0   NaN    NaN            NaN        Algeria  28.03390   \n",
       "4   20   AD  AND   20.0   NaN    NaN            NaN        Andorra  42.50630   \n",
       "\n",
       "       Long_ Combined_Key  Population  \n",
       "0  67.709953  Afghanistan  38928341.0  \n",
       "1  20.168300      Albania   2877800.0  \n",
       "2  23.347000   Antarctica         NaN  \n",
       "3   1.659600      Algeria  43851043.0  \n",
       "4   1.521800      Andorra     77265.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_info = pd.read_csv('ex_datafile/COVID-19-master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv', encoding='utf-8')\n",
    "country_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b144796",
   "metadata": {},
   "source": [
    "#### 5. 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c7bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3483 entries, 0 to 3482\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Province_State_x  3431 non-null   object \n",
      " 1   Country_Region    3483 non-null   object \n",
      " 2   Confirmed         3483 non-null   int64  \n",
      " 3   UID               3457 non-null   float64\n",
      " 4   iso2              3457 non-null   object \n",
      " 5   iso3              3457 non-null   object \n",
      " 6   code3             3457 non-null   float64\n",
      " 7   FIPS              3384 non-null   float64\n",
      " 8   Admin2            3343 non-null   object \n",
      " 9   Province_State_y  3454 non-null   object \n",
      " 10  Lat               3336 non-null   float64\n",
      " 11  Long_             3336 non-null   float64\n",
      " 12  Combined_Key      3457 non-null   object \n",
      " 13  Population        3336 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(7)\n",
      "memory usage: 381.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.merge(csv, country_info, how='left', on='Country_Region')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64c707f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province_State_x     52\n",
       "Country_Region        0\n",
       "Confirmed             0\n",
       "UID                  26\n",
       "iso2                 26\n",
       "iso3                 26\n",
       "code3                26\n",
       "FIPS                 99\n",
       "Admin2              140\n",
       "Province_State_y     29\n",
       "Lat                 147\n",
       "Long_               147\n",
       "Combined_Key         26\n",
       "Population          147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d91a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State_x</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State_y</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State_x  Country_Region  Confirmed  UID iso2 iso3  code3  FIPS  \\\n",
       "0            Anhui  Mainland China          1  NaN  NaN  NaN    NaN   NaN   \n",
       "1          Beijing  Mainland China         14  NaN  NaN  NaN    NaN   NaN   \n",
       "2        Chongqing  Mainland China          6  NaN  NaN  NaN    NaN   NaN   \n",
       "3           Fujian  Mainland China          1  NaN  NaN  NaN    NaN   NaN   \n",
       "4        Guangdong  Mainland China         26  NaN  NaN  NaN    NaN   NaN   \n",
       "\n",
       "  Admin2 Province_State_y  Lat  Long_ Combined_Key  Population  \n",
       "0    NaN              NaN  NaN    NaN          NaN         NaN  \n",
       "1    NaN              NaN  NaN    NaN          NaN         NaN  \n",
       "2    NaN              NaN  NaN    NaN          NaN         NaN  \n",
       "3    NaN              NaN  NaN    NaN          NaN         NaN  \n",
       "4    NaN              NaN  NaN    NaN          NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show = test_df[test_df['iso2'].isnull()]\n",
    "show.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd61fd1",
   "metadata": {},
   "source": [
    "컬럼값 변경하기\n",
    "- Country_Region 국가명이 다양한 경우가 많음\n",
    "- 별도의 json 파일로 만든 후 일관되게 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c00aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mainland China': 'China', 'Macau': 'China', 'South Korea': 'Korea, South', 'Aruba': 'Netherlands', ' Azerbaijan': 'Azerbaijan', 'Bahamas, The': 'Bahamas', 'Cape Verde': 'Cabo Verde', 'Cayman Islands': 'United Kingdom', 'Channel Islands': 'United Kingdom', 'Curacao': 'Netherlands', 'Czech Republic': 'Czechia', 'East Timor': 'Timor-Leste', 'Faroe Islands': 'Denmark', 'French Guiana': 'France', 'Gambia, The': 'Gambia', 'Gibraltar': 'United Kingdom', 'Greenland': 'Denmark', 'Guadeloupe': 'France', 'Guam': 'US', 'Guernsey': 'US', 'Hong Kong': 'China', 'Hong Kong SAR': 'China', 'Iran (Islamic Republic of)': 'Iran', 'Ivory Coast': \"Cote d'Ivoire\", 'Jersey': 'US', 'Macao SAR': 'China', 'Martinique': 'France', 'Mayotte': 'France', 'North Ireland': 'United Kingdom', 'Palestine': 'West Bank and Gaza', 'Puerto Rico': 'US', 'Republic of Ireland': 'Ireland', 'Republic of Korea': 'Korea, South', 'Republic of Moldova': 'Moldova', 'Republic of the Congo': 'Congo (Brazzaville)', 'Reunion': 'France', 'Russian Federation': 'Russia', 'Saint Barthelemy': 'France', 'Saint Martin': 'France', 'St. Martin': 'US', 'Taipei and environs': 'Taiwan', 'The Bahamas': 'Bahamas', 'The Gambia': 'Gambia', 'UK': 'United Kingdom', 'Vatican City': 'Holy See', 'Viet Nam': 'Vietnam', 'occupied Palestinian territory': 'West Bank and Gaza', 'Taiwan*': 'Taiwan', 'Malawi': 'France', 'South Sudan': 'Sudan', 'Western Sahara': 'Morocco', 'Namibia': 'Namibia'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('ex_datafile/COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314a20c",
   "metadata": {},
   "source": [
    "### apply() 함수 사용법\n",
    "- apply() 함수를 사용해서, 특정 컬럼값 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e662e564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   60  100\n",
       "David  70   50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어' : [60, 70],\n",
    "    '수학' : [100, 50]\n",
    "    }, index = ['Dave', 'David']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb4ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    print(type(df_data)) # 타입 확인\n",
    "    print(df_data.index) # 인덱스 확인\n",
    "    print(df_data.values) # 값 확인\n",
    "    return df_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cef6c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['Dave', 'David'], dtype='object')\n",
      "[60 70]\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['Dave', 'David'], dtype='object')\n",
      "[100  50]\n"
     ]
    }
   ],
   "source": [
    "df_func = df.apply(func, axis=0) # 열로 받는다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2374b4",
   "metadata": {},
   "source": [
    "↑<br> 행이 2개인데 3번 출력되는 이유는 apply() 함수 자체가, 첫번째 행에 대해서는 두번 호출하도록 구성되어있기때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c30c0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   60  100\n",
       "David  70   50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어' : [60, 70],\n",
    "    '수학' : [100, 50]\n",
    "    }, index = ['Dave', 'David']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4621a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    df_data['영어'] = 80\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9fd05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93c3ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   80  100\n",
       "David  80   50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8217e78",
   "metadata": {},
   "source": [
    "### apply() 함수 사용해서, 국가 컬럼값 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5da83244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋팅\n",
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv(file_path+'01-22-2020.csv',encoding='utf-8')\n",
    "try : \n",
    "    csv = csv[['Province_State', 'Country_Region', 'Confirmed']] # col 지정해서 데이터프레임 추출\n",
    "\n",
    "except:\n",
    "    csv = csv[['Province/State', 'Country/Region', 'Confirmed']] # 해당 csv 파일의 col확인 후 데이터프레임 추출\n",
    "    csv.columns = ['Province_State', 'Country_Region', 'Confirmed'] # 추출한 데이터프레임 col명 변경\n",
    "\n",
    "csv = csv.dropna(subset=['Confirmed'])\n",
    "csv = csv.astype({'Confirmed' : 'int64'})\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d36c3",
   "metadata": {},
   "source": [
    "- 변경할 국가명을 가지고 있는 json 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6a3344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mainland China': 'China', 'Macau': 'China', 'South Korea': 'Korea, South', 'Aruba': 'Netherlands', ' Azerbaijan': 'Azerbaijan', 'Bahamas, The': 'Bahamas', 'Cape Verde': 'Cabo Verde', 'Cayman Islands': 'United Kingdom', 'Channel Islands': 'United Kingdom', 'Curacao': 'Netherlands', 'Czech Republic': 'Czechia', 'East Timor': 'Timor-Leste', 'Faroe Islands': 'Denmark', 'French Guiana': 'France', 'Gambia, The': 'Gambia', 'Gibraltar': 'United Kingdom', 'Greenland': 'Denmark', 'Guadeloupe': 'France', 'Guam': 'US', 'Guernsey': 'US', 'Hong Kong': 'China', 'Hong Kong SAR': 'China', 'Iran (Islamic Republic of)': 'Iran', 'Ivory Coast': \"Cote d'Ivoire\", 'Jersey': 'US', 'Macao SAR': 'China', 'Martinique': 'France', 'Mayotte': 'France', 'North Ireland': 'United Kingdom', 'Palestine': 'West Bank and Gaza', 'Puerto Rico': 'US', 'Republic of Ireland': 'Ireland', 'Republic of Korea': 'Korea, South', 'Republic of Moldova': 'Moldova', 'Republic of the Congo': 'Congo (Brazzaville)', 'Reunion': 'France', 'Russian Federation': 'Russia', 'Saint Barthelemy': 'France', 'Saint Martin': 'France', 'St. Martin': 'US', 'Taipei and environs': 'Taiwan', 'The Bahamas': 'Bahamas', 'The Gambia': 'Gambia', 'UK': 'United Kingdom', 'Vatican City': 'Holy See', 'Viet Nam': 'Vietnam', 'occupied Palestinian territory': 'West Bank and Gaza', 'Taiwan*': 'Taiwan', 'Malawi': 'France', 'South Sudan': 'Sudan', 'Western Sahara': 'Morocco', 'Namibia': 'Namibia'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('ex_datafile/COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e7179",
   "metadata": {},
   "source": [
    "- Country_Region 이라는 컬럼값을 확인해서, 국가명이 다르게 기재되어 있을 경우에만, 지정한 국가명으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b5aca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "    if row['Country_Region'] in json_data: # dict 데이터에 이게있으면\n",
    "        row['Country_Region'] = json_data[row['Country_Region']]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3bf038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State Country_Region  Confirmed\n",
       "0          Anhui          China          1\n",
       "1        Beijing          China         14\n",
       "2      Chongqing          China          6\n",
       "3         Fujian          China          1\n",
       "5      Guangdong          China         26"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = csv.apply(func, axis=1)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346567b",
   "metadata": {},
   "source": [
    "### 현재까지 한 작업\n",
    "- 여러 데이터에서 Country_Region, Country/Region 이런 컬러명이 있다.\n",
    "- 그래서 csv파일 읽었을 때 컬럼명을 Country/Region 경우 Country_Region 이걸로 변경.\n",
    "- Country_Region 데이터에서 Mainland China, 이렇게 국가가 다르게 되어있는 경우가 있는것을 확인해서 json파일로 {key, value} 형식으로 만든다.\n",
    "- csv파일을 읽어서 County_Region 열의 데이터를 따로 받아서 json파일에서 key가 조회되면 해당 값으로 변경하는 함수를 만든다.\n",
    "- 그다음 apply() 함수를 통해서 열을 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deeeb3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/01/2022'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = '01-01-2022.csv'\n",
    "data= data.replace('-', '/')\n",
    "data\n",
    "date = data.split('.')[0].lstrip('0')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c8daa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Province_State', 'Country_Region', 'Confirmed'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33149dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Province_State', 'Country_Region', '1/01/2022'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.columns = ['Province_State', 'Country_Region', date]\n",
    "csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60d30345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>1/01/2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State Country_Region  1/01/2022\n",
       "0          Anhui          China          1\n",
       "1        Beijing          China         14\n",
       "2      Chongqing          China          6\n",
       "3         Fujian          China          1\n",
       "5      Guangdong          China         26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ebb442",
   "metadata": {},
   "source": [
    "#### 5. 중복 데이터 합치기\n",
    "- groupby() : 그룹별로 데이터를 집계하는 함수\n",
    "    - 동일한 컬럼값으로 묶어서 통계 또는 평균등을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cfb1161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man</td>\n",
       "      <td>lee</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man</td>\n",
       "      <td>kim</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man</td>\n",
       "      <td>kim</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex name  math  english\n",
       "0  Man  lee   100       80\n",
       "1  Man  kim    50       70\n",
       "2  Man  kim    80       50"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'sex' : ['Man', 'Man', 'Man'],\n",
    "    'name' : ['lee', 'kim', 'kim'],\n",
    "    'math' : [100, 50, 80],\n",
    "    'english' : [80, 70, 50]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "479cfa2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ManMan to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ManMan'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\study\\Lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert ManMan to numeric"
     ]
    }
   ],
   "source": [
    "df.groupby('name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a7d9d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee</th>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       math  english\n",
       "name                \n",
       "kim    65.0     60.0\n",
       "lee   100.0     80.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['name','math','english']].groupby('name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89859565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>math</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>MM</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee</th>\n",
       "      <td>M</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  math  english\n",
       "name                   \n",
       "kim   MM   130      120\n",
       "lee    M   100       80"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bc452a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋팅\n",
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv(file_path+'01-22-2020.csv',encoding='utf-8')\n",
    "try : \n",
    "    csv = csv[['Province_State', 'Country_Region', 'Confirmed']] # col 지정해서 데이터프레임 추출\n",
    "\n",
    "except:\n",
    "    csv = csv[['Province/State', 'Country/Region', 'Confirmed']] # 해당 csv 파일의 col확인 후 데이터프레임 추출\n",
    "    csv.columns = ['Province_State', 'Country_Region', 'Confirmed'] # 추출한 데이터프레임 col명 변경\n",
    "\n",
    "csv = csv.dropna(subset=['Confirmed'])\n",
    "csv = csv.astype({'Confirmed' : 'int64'})\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b3cd25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macau</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mainland China</th>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Confirmed\n",
       "Country_Region           \n",
       "Japan                   2\n",
       "Macau                   1\n",
       "Mainland China        547\n",
       "South Korea             1\n",
       "Taiwan                  1\n",
       "Thailand                2\n",
       "US                      1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv[['Country_Region', 'Confirmed']].groupby('Country_Region').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b8031",
   "metadata": {},
   "source": [
    "##### 6. 데이터 전처리하기\n",
    "- 지금까지 한 과정 함수로 만들기\n",
    "- 1. csv 파일 읽기\n",
    "- 2. 'Country_Region', 'Confirmed' 컬럼 가져오기\n",
    "- 3. 'Confirmed' NaN 행 삭제\n",
    "- 4. 'Country_Region' 의 국가명을 여러 파일에 일관되게 변경\n",
    "- 5. 'Confirmed' 데이터 타입을 int64(정수)로 변경\n",
    "- 6. 파일명 기반으로 날짜 문자열로 변환하고, 'Confirmed' 컬럼명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c87d7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋팅\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# json파일 불러옹기\n",
    "with open('ex_datafile/COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "# 컬럼명 변경\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "\n",
    "# csv파일 읽기고 전처리\n",
    "def creat_dateframe(filename):\n",
    "    file_path = 'ex_datafile/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "    csv = pd.read_csv(file_path + filename,encoding='utf-8')                   # 1.\n",
    "    try : \n",
    "        csv = csv[['Province_State', 'Country_Region', 'Confirmed']]           # 2.\n",
    "\n",
    "    except:\n",
    "        csv = csv[['Province/State', 'Country/Region', 'Confirmed']]           # 2.\n",
    "        csv.columns = ['Province_State', 'Country_Region', 'Confirmed'] \n",
    "\n",
    "    csv = csv.dropna(subset=['Confirmed'])                                     # 3.\n",
    "    csv['Country_Region'] = csv.apply(country_name_convert, axis=1)            # 4.\n",
    "    csv = csv.astype({'Confirmed' : 'int64'})                                  # 5.\n",
    "    csv = csv[['Country_Region', 'Confirmed']].groupby('Country_Region').sum() # 6.\n",
    "    \n",
    "    date_column = filename.split('.')[0].lstrip('0').replace('-','/')          # 7.\n",
    "    csv.columns = [date_column]\n",
    "    return csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae5904",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f18b63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = creat_dateframe('01-22-2020.csv')\n",
    "two = creat_dateframe('04-01-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "156c53af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4/01/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                4/01/2020\n",
       "Country_Region           \n",
       "Afghanistan           192\n",
       "Albania               259\n",
       "Algeria               847\n",
       "Andorra               390\n",
       "Angola                  8"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d15cbf",
   "metadata": {},
   "source": [
    "#### 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aac45359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>4/01/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>NaN</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1/22/2020  4/01/2020\n",
       "Country_Region                      \n",
       "Afghanistan           NaN        192\n",
       "Albania               NaN        259\n",
       "Algeria               NaN        847\n",
       "Andorra               NaN        390\n",
       "Angola                NaN          8"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(one, two, how='outer', left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d3476",
   "metadata": {},
   "source": [
    "#### NaN -> 0 으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e6ff0318",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>4/01/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.0</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1/22/2020  4/01/2020\n",
       "Country_Region                      \n",
       "Afghanistan           0.0        192\n",
       "Albania               0.0        259\n",
       "Algeria               0.0        847\n",
       "Andorra               0.0        390\n",
       "Angola                0.0          8"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc532a10",
   "metadata": {},
   "source": [
    "#### 파일 리스트 확인하기\n",
    "- ex) 01-11-2022.csv 확장자 .csv파일만 가지고 리스트에 저장\n",
    "- 저장시 .csv 제거후 sort로 오름차순으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7a5c1f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01-01-2021.csv', '01-01-2022.csv', '01-01-2023.csv', '01-02-2021.csv', '01-02-2022.csv', '01-02-2023.csv', '01-03-2021.csv', '01-03-2022.csv', '01-03-2023.csv', '01-04-2021.csv', '01-04-2022.csv', '01-04-2023.csv', '01-05-2021.csv', '01-05-2022.csv', '01-05-2023.csv', '01-06-2021.csv', '01-06-2022.csv', '01-06-2023.csv', '01-07-2021.csv', '01-07-2022.csv', '01-07-2023.csv', '01-08-2021.csv', '01-08-2022.csv', '01-08-2023.csv', '01-09-2021.csv', '01-09-2022.csv', '01-09-2023.csv', '01-10-2021.csv', '01-10-2022.csv', '01-10-2023.csv', '01-11-2021.csv', '01-11-2022.csv', '01-11-2023.csv', '01-12-2021.csv', '01-12-2022.csv', '01-12-2023.csv', '01-13-2021.csv', '01-13-2022.csv', '01-13-2023.csv', '01-14-2021.csv', '01-14-2022.csv', '01-14-2023.csv', '01-15-2021.csv', '01-15-2022.csv', '01-15-2023.csv', '01-16-2021.csv', '01-16-2022.csv', '01-16-2023.csv', '01-17-2021.csv', '01-17-2022.csv', '01-17-2023.csv', '01-18-2021.csv', '01-18-2022.csv', '01-18-2023.csv', '01-19-2021.csv', '01-19-2022.csv', '01-19-2023.csv', '01-20-2021.csv', '01-20-2022.csv', '01-20-2023.csv', '01-21-2021.csv', '01-21-2022.csv', '01-21-2023.csv', '01-22-2020.csv', '01-22-2021.csv', '01-22-2022.csv', '01-22-2023.csv', '01-23-2020.csv', '01-23-2021.csv', '01-23-2022.csv', '01-23-2023.csv', '01-24-2020.csv', '01-24-2021.csv', '01-24-2022.csv', '01-24-2023.csv', '01-25-2020.csv', '01-25-2021.csv', '01-25-2022.csv', '01-25-2023.csv', '01-26-2020.csv', '01-26-2021.csv', '01-26-2022.csv', '01-26-2023.csv', '01-27-2020.csv', '01-27-2021.csv', '01-27-2022.csv', '01-27-2023.csv', '01-28-2020.csv', '01-28-2021.csv', '01-28-2022.csv', '01-28-2023.csv', '01-29-2020.csv', '01-29-2021.csv', '01-29-2022.csv', '01-29-2023.csv', '01-30-2020.csv', '01-30-2021.csv', '01-30-2022.csv', '01-30-2023.csv', '01-31-2020.csv', '01-31-2021.csv', '01-31-2022.csv', '01-31-2023.csv', '02-01-2020.csv', '02-01-2021.csv', '02-01-2022.csv', '02-01-2023.csv', '02-02-2020.csv', '02-02-2021.csv', '02-02-2022.csv', '02-02-2023.csv', '02-03-2020.csv', '02-03-2021.csv', '02-03-2022.csv', '02-03-2023.csv', '02-04-2020.csv', '02-04-2021.csv', '02-04-2022.csv', '02-04-2023.csv', '02-05-2020.csv', '02-05-2021.csv', '02-05-2022.csv', '02-05-2023.csv', '02-06-2020.csv', '02-06-2021.csv', '02-06-2022.csv', '02-06-2023.csv', '02-07-2020.csv', '02-07-2021.csv', '02-07-2022.csv', '02-07-2023.csv', '02-08-2020.csv', '02-08-2021.csv', '02-08-2022.csv', '02-08-2023.csv', '02-09-2020.csv', '02-09-2021.csv', '02-09-2022.csv', '02-09-2023.csv', '02-10-2020.csv', '02-10-2021.csv', '02-10-2022.csv', '02-10-2023.csv', '02-11-2020.csv', '02-11-2021.csv', '02-11-2022.csv', '02-11-2023.csv', '02-12-2020.csv', '02-12-2021.csv', '02-12-2022.csv', '02-12-2023.csv', '02-13-2020.csv', '02-13-2021.csv', '02-13-2022.csv', '02-13-2023.csv', '02-14-2020.csv', '02-14-2021.csv', '02-14-2022.csv', '02-14-2023.csv', '02-15-2020.csv', '02-15-2021.csv', '02-15-2022.csv', '02-15-2023.csv', '02-16-2020.csv', '02-16-2021.csv', '02-16-2022.csv', '02-16-2023.csv', '02-17-2020.csv', '02-17-2021.csv', '02-17-2022.csv', '02-17-2023.csv', '02-18-2020.csv', '02-18-2021.csv', '02-18-2022.csv', '02-18-2023.csv', '02-19-2020.csv', '02-19-2021.csv', '02-19-2022.csv', '02-19-2023.csv', '02-20-2020.csv', '02-20-2021.csv', '02-20-2022.csv', '02-20-2023.csv', '02-21-2020.csv', '02-21-2021.csv', '02-21-2022.csv', '02-21-2023.csv', '02-22-2020.csv', '02-22-2021.csv', '02-22-2022.csv', '02-22-2023.csv', '02-23-2020.csv', '02-23-2021.csv', '02-23-2022.csv', '02-23-2023.csv', '02-24-2020.csv', '02-24-2021.csv', '02-24-2022.csv', '02-24-2023.csv', '02-25-2020.csv', '02-25-2021.csv', '02-25-2022.csv', '02-25-2023.csv', '02-26-2020.csv', '02-26-2021.csv', '02-26-2022.csv', '02-26-2023.csv', '02-27-2020.csv', '02-27-2021.csv', '02-27-2022.csv', '02-27-2023.csv', '02-28-2020.csv', '02-28-2021.csv', '02-28-2022.csv', '02-28-2023.csv', '02-29-2020.csv', '03-01-2020.csv', '03-01-2021.csv', '03-01-2022.csv', '03-01-2023.csv', '03-02-2020.csv', '03-02-2021.csv', '03-02-2022.csv', '03-02-2023.csv', '03-03-2020.csv', '03-03-2021.csv', '03-03-2022.csv', '03-03-2023.csv', '03-04-2020.csv', '03-04-2021.csv', '03-04-2022.csv', '03-04-2023.csv', '03-05-2020.csv', '03-05-2021.csv', '03-05-2022.csv', '03-05-2023.csv', '03-06-2020.csv', '03-06-2021.csv', '03-06-2022.csv', '03-06-2023.csv', '03-07-2020.csv', '03-07-2021.csv', '03-07-2022.csv', '03-07-2023.csv', '03-08-2020.csv', '03-08-2021.csv', '03-08-2022.csv', '03-08-2023.csv', '03-09-2020.csv', '03-09-2021.csv', '03-09-2022.csv', '03-09-2023.csv', '03-10-2020.csv', '03-10-2021.csv', '03-10-2022.csv', '03-11-2020.csv', '03-11-2021.csv', '03-11-2022.csv', '03-12-2020.csv', '03-12-2021.csv', '03-12-2022.csv', '03-13-2020.csv', '03-13-2021.csv', '03-13-2022.csv', '03-14-2020.csv', '03-14-2021.csv', '03-14-2022.csv', '03-15-2020.csv', '03-15-2021.csv', '03-15-2022.csv', '03-16-2020.csv', '03-16-2021.csv', '03-16-2022.csv', '03-17-2020.csv', '03-17-2021.csv', '03-17-2022.csv', '03-18-2020.csv', '03-18-2021.csv', '03-18-2022.csv', '03-19-2020.csv', '03-19-2021.csv', '03-19-2022.csv', '03-20-2020.csv', '03-20-2021.csv', '03-20-2022.csv', '03-21-2020.csv', '03-21-2021.csv', '03-21-2022.csv', '03-22-2020.csv', '03-22-2021.csv', '03-22-2022.csv', '03-23-2020.csv', '03-23-2021.csv', '03-23-2022.csv', '03-24-2020.csv', '03-24-2021.csv', '03-24-2022.csv', '03-25-2020.csv', '03-25-2021.csv', '03-25-2022.csv', '03-26-2020.csv', '03-26-2021.csv', '03-26-2022.csv', '03-27-2020.csv', '03-27-2021.csv', '03-27-2022.csv', '03-28-2020.csv', '03-28-2021.csv', '03-28-2022.csv', '03-29-2020.csv', '03-29-2021.csv', '03-29-2022.csv', '03-30-2020.csv', '03-30-2021.csv', '03-30-2022.csv', '03-31-2020.csv', '03-31-2021.csv', '03-31-2022.csv', '04-01-2020.csv', '04-01-2021.csv', '04-01-2022.csv', '04-02-2020.csv', '04-02-2021.csv', '04-02-2022.csv', '04-03-2020.csv', '04-03-2021.csv', '04-03-2022.csv', '04-04-2020.csv', '04-04-2021.csv', '04-04-2022.csv', '04-05-2020.csv', '04-05-2021.csv', '04-05-2022.csv', '04-06-2020.csv', '04-06-2021.csv', '04-06-2022.csv', '04-07-2020.csv', '04-07-2021.csv', '04-07-2022.csv', '04-08-2020.csv', '04-08-2021.csv', '04-08-2022.csv', '04-09-2020.csv', '04-09-2021.csv', '04-09-2022.csv', '04-10-2020.csv', '04-10-2021.csv', '04-10-2022.csv', '04-11-2020.csv', '04-11-2021.csv', '04-11-2022.csv', '04-12-2020.csv', '04-12-2021.csv', '04-12-2022.csv', '04-13-2020.csv', '04-13-2021.csv', '04-13-2022.csv', '04-14-2020.csv', '04-14-2021.csv', '04-14-2022.csv', '04-15-2020.csv', '04-15-2021.csv', '04-15-2022.csv', '04-16-2020.csv', '04-16-2021.csv', '04-16-2022.csv', '04-17-2020.csv', '04-17-2021.csv', '04-17-2022.csv', '04-18-2020.csv', '04-18-2021.csv', '04-18-2022.csv', '04-19-2020.csv', '04-19-2021.csv', '04-19-2022.csv', '04-20-2020.csv', '04-20-2021.csv', '04-20-2022.csv', '04-21-2020.csv', '04-21-2021.csv', '04-21-2022.csv', '04-22-2020.csv', '04-22-2021.csv', '04-22-2022.csv', '04-23-2020.csv', '04-23-2021.csv', '04-23-2022.csv', '04-24-2020.csv', '04-24-2021.csv', '04-24-2022.csv', '04-25-2020.csv', '04-25-2021.csv', '04-25-2022.csv', '04-26-2020.csv', '04-26-2021.csv', '04-26-2022.csv', '04-27-2020.csv', '04-27-2021.csv', '04-27-2022.csv', '04-28-2020.csv', '04-28-2021.csv', '04-28-2022.csv', '04-29-2020.csv', '04-29-2021.csv', '04-29-2022.csv', '04-30-2020.csv', '04-30-2021.csv', '04-30-2022.csv', '05-01-2020.csv', '05-01-2021.csv', '05-01-2022.csv', '05-02-2020.csv', '05-02-2021.csv', '05-02-2022.csv', '05-03-2020.csv', '05-03-2021.csv', '05-03-2022.csv', '05-04-2020.csv', '05-04-2021.csv', '05-04-2022.csv', '05-05-2020.csv', '05-05-2021.csv', '05-05-2022.csv', '05-06-2020.csv', '05-06-2021.csv', '05-06-2022.csv', '05-07-2020.csv', '05-07-2021.csv', '05-07-2022.csv', '05-08-2020.csv', '05-08-2021.csv', '05-08-2022.csv', '05-09-2020.csv', '05-09-2021.csv', '05-09-2022.csv', '05-10-2020.csv', '05-10-2021.csv', '05-10-2022.csv', '05-11-2020.csv', '05-11-2021.csv', '05-11-2022.csv', '05-12-2020.csv', '05-12-2021.csv', '05-12-2022.csv', '05-13-2020.csv', '05-13-2021.csv', '05-13-2022.csv', '05-14-2020.csv', '05-14-2021.csv', '05-14-2022.csv', '05-15-2020.csv', '05-15-2021.csv', '05-15-2022.csv', '05-16-2020.csv', '05-16-2021.csv', '05-16-2022.csv', '05-17-2020.csv', '05-17-2021.csv', '05-17-2022.csv', '05-18-2020.csv', '05-18-2021.csv', '05-18-2022.csv', '05-19-2020.csv', '05-19-2021.csv', '05-19-2022.csv', '05-20-2020.csv', '05-20-2021.csv', '05-20-2022.csv', '05-21-2020.csv', '05-21-2021.csv', '05-21-2022.csv', '05-22-2020.csv', '05-22-2021.csv', '05-22-2022.csv', '05-23-2020.csv', '05-23-2021.csv', '05-23-2022.csv', '05-24-2020.csv', '05-24-2021.csv', '05-24-2022.csv', '05-25-2020.csv', '05-25-2021.csv', '05-25-2022.csv', '05-26-2020.csv', '05-26-2021.csv', '05-26-2022.csv', '05-27-2020.csv', '05-27-2021.csv', '05-27-2022.csv', '05-28-2020.csv', '05-28-2021.csv', '05-28-2022.csv', '05-29-2020.csv', '05-29-2021.csv', '05-29-2022.csv', '05-30-2020.csv', '05-30-2021.csv', '05-30-2022.csv', '05-31-2020.csv', '05-31-2021.csv', '05-31-2022.csv', '06-01-2020.csv', '06-01-2021.csv', '06-01-2022.csv', '06-02-2020.csv', '06-02-2021.csv', '06-02-2022.csv', '06-03-2020.csv', '06-03-2021.csv', '06-03-2022.csv', '06-04-2020.csv', '06-04-2021.csv', '06-04-2022.csv', '06-05-2020.csv', '06-05-2021.csv', '06-05-2022.csv', '06-06-2020.csv', '06-06-2021.csv', '06-06-2022.csv', '06-07-2020.csv', '06-07-2021.csv', '06-07-2022.csv', '06-08-2020.csv', '06-08-2021.csv', '06-08-2022.csv', '06-09-2020.csv', '06-09-2021.csv', '06-09-2022.csv', '06-10-2020.csv', '06-10-2021.csv', '06-10-2022.csv', '06-11-2020.csv', '06-11-2021.csv', '06-11-2022.csv', '06-12-2020.csv', '06-12-2021.csv', '06-12-2022.csv', '06-13-2020.csv', '06-13-2021.csv', '06-13-2022.csv', '06-14-2020.csv', '06-14-2021.csv', '06-14-2022.csv', '06-15-2020.csv', '06-15-2021.csv', '06-15-2022.csv', '06-16-2020.csv', '06-16-2021.csv', '06-16-2022.csv', '06-17-2020.csv', '06-17-2021.csv', '06-17-2022.csv', '06-18-2020.csv', '06-18-2021.csv', '06-18-2022.csv', '06-19-2020.csv', '06-19-2021.csv', '06-19-2022.csv', '06-20-2020.csv', '06-20-2021.csv', '06-20-2022.csv', '06-21-2020.csv', '06-21-2021.csv', '06-21-2022.csv', '06-22-2020.csv', '06-22-2021.csv', '06-22-2022.csv', '06-23-2020.csv', '06-23-2021.csv', '06-23-2022.csv', '06-24-2020.csv', '06-24-2021.csv', '06-24-2022.csv', '06-25-2020.csv', '06-25-2021.csv', '06-25-2022.csv', '06-26-2020.csv', '06-26-2021.csv', '06-26-2022.csv', '06-27-2020.csv', '06-27-2021.csv', '06-27-2022.csv', '06-28-2020.csv', '06-28-2021.csv', '06-28-2022.csv', '06-29-2020.csv', '06-29-2021.csv', '06-29-2022.csv', '06-30-2020.csv', '06-30-2021.csv', '06-30-2022.csv', '07-01-2020.csv', '07-01-2021.csv', '07-01-2022.csv', '07-02-2020.csv', '07-02-2021.csv', '07-02-2022.csv', '07-03-2020.csv', '07-03-2021.csv', '07-03-2022.csv', '07-04-2020.csv', '07-04-2021.csv', '07-04-2022.csv', '07-05-2020.csv', '07-05-2021.csv', '07-05-2022.csv', '07-06-2020.csv', '07-06-2021.csv', '07-06-2022.csv', '07-07-2020.csv', '07-07-2021.csv', '07-07-2022.csv', '07-08-2020.csv', '07-08-2021.csv', '07-08-2022.csv', '07-09-2020.csv', '07-09-2021.csv', '07-09-2022.csv', '07-10-2020.csv', '07-10-2021.csv', '07-10-2022.csv', '07-11-2020.csv', '07-11-2021.csv', '07-11-2022.csv', '07-12-2020.csv', '07-12-2021.csv', '07-12-2022.csv', '07-13-2020.csv', '07-13-2021.csv', '07-13-2022.csv', '07-14-2020.csv', '07-14-2021.csv', '07-14-2022.csv', '07-15-2020.csv', '07-15-2021.csv', '07-15-2022.csv', '07-16-2020.csv', '07-16-2021.csv', '07-16-2022.csv', '07-17-2020.csv', '07-17-2021.csv', '07-17-2022.csv', '07-18-2020.csv', '07-18-2021.csv', '07-18-2022.csv', '07-19-2020.csv', '07-19-2021.csv', '07-19-2022.csv', '07-20-2020.csv', '07-20-2021.csv', '07-20-2022.csv', '07-21-2020.csv', '07-21-2021.csv', '07-21-2022.csv', '07-22-2020.csv', '07-22-2021.csv', '07-22-2022.csv', '07-23-2020.csv', '07-23-2021.csv', '07-23-2022.csv', '07-24-2020.csv', '07-24-2021.csv', '07-24-2022.csv', '07-25-2020.csv', '07-25-2021.csv', '07-25-2022.csv', '07-26-2020.csv', '07-26-2021.csv', '07-26-2022.csv', '07-27-2020.csv', '07-27-2021.csv', '07-27-2022.csv', '07-28-2020.csv', '07-28-2021.csv', '07-28-2022.csv', '07-29-2020.csv', '07-29-2021.csv', '07-29-2022.csv', '07-30-2020.csv', '07-30-2021.csv', '07-30-2022.csv', '07-31-2020.csv', '07-31-2021.csv', '07-31-2022.csv', '08-01-2020.csv', '08-01-2021.csv', '08-01-2022.csv', '08-02-2020.csv', '08-02-2021.csv', '08-02-2022.csv', '08-03-2020.csv', '08-03-2021.csv', '08-03-2022.csv', '08-04-2020.csv', '08-04-2021.csv', '08-04-2022.csv', '08-05-2020.csv', '08-05-2021.csv', '08-05-2022.csv', '08-06-2020.csv', '08-06-2021.csv', '08-06-2022.csv', '08-07-2020.csv', '08-07-2021.csv', '08-07-2022.csv', '08-08-2020.csv', '08-08-2021.csv', '08-08-2022.csv', '08-09-2020.csv', '08-09-2021.csv', '08-09-2022.csv', '08-10-2020.csv', '08-10-2021.csv', '08-10-2022.csv', '08-11-2020.csv', '08-11-2021.csv', '08-11-2022.csv', '08-12-2020.csv', '08-12-2021.csv', '08-12-2022.csv', '08-13-2020.csv', '08-13-2021.csv', '08-13-2022.csv', '08-14-2020.csv', '08-14-2021.csv', '08-14-2022.csv', '08-15-2020.csv', '08-15-2021.csv', '08-15-2022.csv', '08-16-2020.csv', '08-16-2021.csv', '08-16-2022.csv', '08-17-2020.csv', '08-17-2021.csv', '08-17-2022.csv', '08-18-2020.csv', '08-18-2021.csv', '08-18-2022.csv', '08-19-2020.csv', '08-19-2021.csv', '08-19-2022.csv', '08-20-2020.csv', '08-20-2021.csv', '08-20-2022.csv', '08-21-2020.csv', '08-21-2021.csv', '08-21-2022.csv', '08-22-2020.csv', '08-22-2021.csv', '08-22-2022.csv', '08-23-2020.csv', '08-23-2021.csv', '08-23-2022.csv', '08-24-2020.csv', '08-24-2021.csv', '08-24-2022.csv', '08-25-2020.csv', '08-25-2021.csv', '08-25-2022.csv', '08-26-2020.csv', '08-26-2021.csv', '08-26-2022.csv', '08-27-2020.csv', '08-27-2021.csv', '08-27-2022.csv', '08-28-2020.csv', '08-28-2021.csv', '08-28-2022.csv', '08-29-2020.csv', '08-29-2021.csv', '08-29-2022.csv', '08-30-2020.csv', '08-30-2021.csv', '08-30-2022.csv', '08-31-2020.csv', '08-31-2021.csv', '08-31-2022.csv', '09-01-2020.csv', '09-01-2021.csv', '09-01-2022.csv', '09-02-2020.csv', '09-02-2021.csv', '09-02-2022.csv', '09-03-2020.csv', '09-03-2021.csv', '09-03-2022.csv', '09-04-2020.csv', '09-04-2021.csv', '09-04-2022.csv', '09-05-2020.csv', '09-05-2021.csv', '09-05-2022.csv', '09-06-2020.csv', '09-06-2021.csv', '09-06-2022.csv', '09-07-2020.csv', '09-07-2021.csv', '09-07-2022.csv', '09-08-2020.csv', '09-08-2021.csv', '09-08-2022.csv', '09-09-2020.csv', '09-09-2021.csv', '09-09-2022.csv', '09-10-2020.csv', '09-10-2021.csv', '09-10-2022.csv', '09-11-2020.csv', '09-11-2021.csv', '09-11-2022.csv', '09-12-2020.csv', '09-12-2021.csv', '09-12-2022.csv', '09-13-2020.csv', '09-13-2021.csv', '09-13-2022.csv', '09-14-2020.csv', '09-14-2021.csv', '09-14-2022.csv', '09-15-2020.csv', '09-15-2021.csv', '09-15-2022.csv', '09-16-2020.csv', '09-16-2021.csv', '09-16-2022.csv', '09-17-2020.csv', '09-17-2021.csv', '09-17-2022.csv', '09-18-2020.csv', '09-18-2021.csv', '09-18-2022.csv', '09-19-2020.csv', '09-19-2021.csv', '09-19-2022.csv', '09-20-2020.csv', '09-20-2021.csv', '09-20-2022.csv', '09-21-2020.csv', '09-21-2021.csv', '09-21-2022.csv', '09-22-2020.csv', '09-22-2021.csv', '09-22-2022.csv', '09-23-2020.csv', '09-23-2021.csv', '09-23-2022.csv', '09-24-2020.csv', '09-24-2021.csv', '09-24-2022.csv', '09-25-2020.csv', '09-25-2021.csv', '09-25-2022.csv', '09-26-2020.csv', '09-26-2021.csv', '09-26-2022.csv', '09-27-2020.csv', '09-27-2021.csv', '09-27-2022.csv', '09-28-2020.csv', '09-28-2021.csv', '09-28-2022.csv', '09-29-2020.csv', '09-29-2021.csv', '09-29-2022.csv', '09-30-2020.csv', '09-30-2021.csv', '09-30-2022.csv', '10-01-2020.csv', '10-01-2021.csv', '10-01-2022.csv', '10-02-2020.csv', '10-02-2021.csv', '10-02-2022.csv', '10-03-2020.csv', '10-03-2021.csv', '10-03-2022.csv', '10-04-2020.csv', '10-04-2021.csv', '10-04-2022.csv', '10-05-2020.csv', '10-05-2021.csv', '10-05-2022.csv', '10-06-2020.csv', '10-06-2021.csv', '10-06-2022.csv', '10-07-2020.csv', '10-07-2021.csv', '10-07-2022.csv', '10-08-2020.csv', '10-08-2021.csv', '10-08-2022.csv', '10-09-2020.csv', '10-09-2021.csv', '10-09-2022.csv', '10-10-2020.csv', '10-10-2021.csv', '10-10-2022.csv', '10-11-2020.csv', '10-11-2021.csv', '10-11-2022.csv', '10-12-2020.csv', '10-12-2021.csv', '10-12-2022.csv', '10-13-2020.csv', '10-13-2021.csv', '10-13-2022.csv', '10-14-2020.csv', '10-14-2021.csv', '10-14-2022.csv', '10-15-2020.csv', '10-15-2021.csv', '10-15-2022.csv', '10-16-2020.csv', '10-16-2021.csv', '10-16-2022.csv', '10-17-2020.csv', '10-17-2021.csv', '10-17-2022.csv', '10-18-2020.csv', '10-18-2021.csv', '10-18-2022.csv', '10-19-2020.csv', '10-19-2021.csv', '10-19-2022.csv', '10-20-2020.csv', '10-20-2021.csv', '10-20-2022.csv', '10-21-2020.csv', '10-21-2021.csv', '10-21-2022.csv', '10-22-2020.csv', '10-22-2021.csv', '10-22-2022.csv', '10-23-2020.csv', '10-23-2021.csv', '10-23-2022.csv', '10-24-2020.csv', '10-24-2021.csv', '10-24-2022.csv', '10-25-2020.csv', '10-25-2021.csv', '10-25-2022.csv', '10-26-2020.csv', '10-26-2021.csv', '10-26-2022.csv', '10-27-2020.csv', '10-27-2021.csv', '10-27-2022.csv', '10-28-2020.csv', '10-28-2021.csv', '10-28-2022.csv', '10-29-2020.csv', '10-29-2021.csv', '10-29-2022.csv', '10-30-2020.csv', '10-30-2021.csv', '10-30-2022.csv', '10-31-2020.csv', '10-31-2021.csv', '10-31-2022.csv', '11-01-2020.csv', '11-01-2021.csv', '11-01-2022.csv', '11-02-2020.csv', '11-02-2021.csv', '11-02-2022.csv', '11-03-2020.csv', '11-03-2021.csv', '11-03-2022.csv', '11-04-2020.csv', '11-04-2021.csv', '11-04-2022.csv', '11-05-2020.csv', '11-05-2021.csv', '11-05-2022.csv', '11-06-2020.csv', '11-06-2021.csv', '11-06-2022.csv', '11-07-2020.csv', '11-07-2021.csv', '11-07-2022.csv', '11-08-2020.csv', '11-08-2021.csv', '11-08-2022.csv', '11-09-2020.csv', '11-09-2021.csv', '11-09-2022.csv', '11-10-2020.csv', '11-10-2021.csv', '11-10-2022.csv', '11-11-2020.csv', '11-11-2021.csv', '11-11-2022.csv', '11-12-2020.csv', '11-12-2021.csv', '11-12-2022.csv', '11-13-2020.csv', '11-13-2021.csv', '11-13-2022.csv', '11-14-2020.csv', '11-14-2021.csv', '11-14-2022.csv', '11-15-2020.csv', '11-15-2021.csv', '11-15-2022.csv', '11-16-2020.csv', '11-16-2021.csv', '11-16-2022.csv', '11-17-2020.csv', '11-17-2021.csv', '11-17-2022.csv', '11-18-2020.csv', '11-18-2021.csv', '11-18-2022.csv', '11-19-2020.csv', '11-19-2021.csv', '11-19-2022.csv', '11-20-2020.csv', '11-20-2021.csv', '11-20-2022.csv', '11-21-2020.csv', '11-21-2021.csv', '11-21-2022.csv', '11-22-2020.csv', '11-22-2021.csv', '11-22-2022.csv', '11-23-2020.csv', '11-23-2021.csv', '11-23-2022.csv', '11-24-2020.csv', '11-24-2021.csv', '11-24-2022.csv', '11-25-2020.csv', '11-25-2021.csv', '11-25-2022.csv', '11-26-2020.csv', '11-26-2021.csv', '11-26-2022.csv', '11-27-2020.csv', '11-27-2021.csv', '11-27-2022.csv', '11-28-2020.csv', '11-28-2021.csv', '11-28-2022.csv', '11-29-2020.csv', '11-29-2021.csv', '11-29-2022.csv', '11-30-2020.csv', '11-30-2021.csv', '11-30-2022.csv', '12-01-2020.csv', '12-01-2021.csv', '12-01-2022.csv', '12-02-2020.csv', '12-02-2021.csv', '12-02-2022.csv', '12-03-2020.csv', '12-03-2021.csv', '12-03-2022.csv', '12-04-2020.csv', '12-04-2021.csv', '12-04-2022.csv', '12-05-2020.csv', '12-05-2021.csv', '12-05-2022.csv', '12-06-2020.csv', '12-06-2021.csv', '12-06-2022.csv', '12-07-2020.csv', '12-07-2021.csv', '12-07-2022.csv', '12-08-2020.csv', '12-08-2021.csv', '12-08-2022.csv', '12-09-2020.csv', '12-09-2021.csv', '12-09-2022.csv', '12-10-2020.csv', '12-10-2021.csv', '12-10-2022.csv', '12-11-2020.csv', '12-11-2021.csv', '12-11-2022.csv', '12-12-2020.csv', '12-12-2021.csv', '12-12-2022.csv', '12-13-2020.csv', '12-13-2021.csv', '12-13-2022.csv', '12-14-2020.csv', '12-14-2021.csv', '12-14-2022.csv', '12-15-2020.csv', '12-15-2021.csv', '12-15-2022.csv', '12-16-2020.csv', '12-16-2021.csv', '12-16-2022.csv', '12-17-2020.csv', '12-17-2021.csv', '12-17-2022.csv', '12-18-2020.csv', '12-18-2021.csv', '12-18-2022.csv', '12-19-2020.csv', '12-19-2021.csv', '12-19-2022.csv', '12-20-2020.csv', '12-20-2021.csv', '12-20-2022.csv', '12-21-2020.csv', '12-21-2021.csv', '12-21-2022.csv', '12-22-2020.csv', '12-22-2021.csv', '12-22-2022.csv', '12-23-2020.csv', '12-23-2021.csv', '12-23-2022.csv', '12-24-2020.csv', '12-24-2021.csv', '12-24-2022.csv', '12-25-2020.csv', '12-25-2021.csv', '12-25-2022.csv', '12-26-2020.csv', '12-26-2021.csv', '12-26-2022.csv', '12-27-2020.csv', '12-27-2021.csv', '12-27-2022.csv', '12-28-2020.csv', '12-28-2021.csv', '12-28-2022.csv', '12-29-2020.csv', '12-29-2021.csv', '12-29-2022.csv', '12-30-2020.csv', '12-30-2021.csv', '12-30-2022.csv', '12-31-2020.csv', '12-31-2021.csv', '12-31-2022.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = 'ex_datafile/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "\n",
    "file_list = os.listdir(file_path)\n",
    "csv_list = list()\n",
    "\n",
    "for file in file_list:\n",
    "    if file.split(\".\")[-1] == 'csv':\n",
    "        csv_list.append(file)\n",
    "\n",
    "print (csv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5189889",
   "metadata": {},
   "source": [
    "#### 리스트 정렬\n",
    "- sort() : 오름차순 정렬(default)\n",
    "- sort(reverse=True) : 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d5b5d61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-01-2021.csv',\n",
       " '01-01-2022.csv',\n",
       " '01-01-2023.csv',\n",
       " '01-02-2021.csv',\n",
       " '01-02-2022.csv',\n",
       " '01-02-2023.csv',\n",
       " '01-03-2021.csv',\n",
       " '01-03-2022.csv',\n",
       " '01-03-2023.csv',\n",
       " '01-04-2021.csv',\n",
       " '01-04-2022.csv',\n",
       " '01-04-2023.csv',\n",
       " '01-05-2021.csv',\n",
       " '01-05-2022.csv',\n",
       " '01-05-2023.csv',\n",
       " '01-06-2021.csv',\n",
       " '01-06-2022.csv',\n",
       " '01-06-2023.csv',\n",
       " '01-07-2021.csv',\n",
       " '01-07-2022.csv',\n",
       " '01-07-2023.csv',\n",
       " '01-08-2021.csv',\n",
       " '01-08-2022.csv',\n",
       " '01-08-2023.csv',\n",
       " '01-09-2021.csv',\n",
       " '01-09-2022.csv',\n",
       " '01-09-2023.csv',\n",
       " '01-10-2021.csv',\n",
       " '01-10-2022.csv',\n",
       " '01-10-2023.csv',\n",
       " '01-11-2021.csv',\n",
       " '01-11-2022.csv',\n",
       " '01-11-2023.csv',\n",
       " '01-12-2021.csv',\n",
       " '01-12-2022.csv',\n",
       " '01-12-2023.csv',\n",
       " '01-13-2021.csv',\n",
       " '01-13-2022.csv',\n",
       " '01-13-2023.csv',\n",
       " '01-14-2021.csv',\n",
       " '01-14-2022.csv',\n",
       " '01-14-2023.csv',\n",
       " '01-15-2021.csv',\n",
       " '01-15-2022.csv',\n",
       " '01-15-2023.csv',\n",
       " '01-16-2021.csv',\n",
       " '01-16-2022.csv',\n",
       " '01-16-2023.csv',\n",
       " '01-17-2021.csv',\n",
       " '01-17-2022.csv',\n",
       " '01-17-2023.csv',\n",
       " '01-18-2021.csv',\n",
       " '01-18-2022.csv',\n",
       " '01-18-2023.csv',\n",
       " '01-19-2021.csv',\n",
       " '01-19-2022.csv',\n",
       " '01-19-2023.csv',\n",
       " '01-20-2021.csv',\n",
       " '01-20-2022.csv',\n",
       " '01-20-2023.csv',\n",
       " '01-21-2021.csv',\n",
       " '01-21-2022.csv',\n",
       " '01-21-2023.csv',\n",
       " '01-22-2020.csv',\n",
       " '01-22-2021.csv',\n",
       " '01-22-2022.csv',\n",
       " '01-22-2023.csv',\n",
       " '01-23-2020.csv',\n",
       " '01-23-2021.csv',\n",
       " '01-23-2022.csv',\n",
       " '01-23-2023.csv',\n",
       " '01-24-2020.csv',\n",
       " '01-24-2021.csv',\n",
       " '01-24-2022.csv',\n",
       " '01-24-2023.csv',\n",
       " '01-25-2020.csv',\n",
       " '01-25-2021.csv',\n",
       " '01-25-2022.csv',\n",
       " '01-25-2023.csv',\n",
       " '01-26-2020.csv',\n",
       " '01-26-2021.csv',\n",
       " '01-26-2022.csv',\n",
       " '01-26-2023.csv',\n",
       " '01-27-2020.csv',\n",
       " '01-27-2021.csv',\n",
       " '01-27-2022.csv',\n",
       " '01-27-2023.csv',\n",
       " '01-28-2020.csv',\n",
       " '01-28-2021.csv',\n",
       " '01-28-2022.csv',\n",
       " '01-28-2023.csv',\n",
       " '01-29-2020.csv',\n",
       " '01-29-2021.csv',\n",
       " '01-29-2022.csv',\n",
       " '01-29-2023.csv',\n",
       " '01-30-2020.csv',\n",
       " '01-30-2021.csv',\n",
       " '01-30-2022.csv',\n",
       " '01-30-2023.csv',\n",
       " '01-31-2020.csv',\n",
       " '01-31-2021.csv',\n",
       " '01-31-2022.csv',\n",
       " '01-31-2023.csv',\n",
       " '02-01-2020.csv',\n",
       " '02-01-2021.csv',\n",
       " '02-01-2022.csv',\n",
       " '02-01-2023.csv',\n",
       " '02-02-2020.csv',\n",
       " '02-02-2021.csv',\n",
       " '02-02-2022.csv',\n",
       " '02-02-2023.csv',\n",
       " '02-03-2020.csv',\n",
       " '02-03-2021.csv',\n",
       " '02-03-2022.csv',\n",
       " '02-03-2023.csv',\n",
       " '02-04-2020.csv',\n",
       " '02-04-2021.csv',\n",
       " '02-04-2022.csv',\n",
       " '02-04-2023.csv',\n",
       " '02-05-2020.csv',\n",
       " '02-05-2021.csv',\n",
       " '02-05-2022.csv',\n",
       " '02-05-2023.csv',\n",
       " '02-06-2020.csv',\n",
       " '02-06-2021.csv',\n",
       " '02-06-2022.csv',\n",
       " '02-06-2023.csv',\n",
       " '02-07-2020.csv',\n",
       " '02-07-2021.csv',\n",
       " '02-07-2022.csv',\n",
       " '02-07-2023.csv',\n",
       " '02-08-2020.csv',\n",
       " '02-08-2021.csv',\n",
       " '02-08-2022.csv',\n",
       " '02-08-2023.csv',\n",
       " '02-09-2020.csv',\n",
       " '02-09-2021.csv',\n",
       " '02-09-2022.csv',\n",
       " '02-09-2023.csv',\n",
       " '02-10-2020.csv',\n",
       " '02-10-2021.csv',\n",
       " '02-10-2022.csv',\n",
       " '02-10-2023.csv',\n",
       " '02-11-2020.csv',\n",
       " '02-11-2021.csv',\n",
       " '02-11-2022.csv',\n",
       " '02-11-2023.csv',\n",
       " '02-12-2020.csv',\n",
       " '02-12-2021.csv',\n",
       " '02-12-2022.csv',\n",
       " '02-12-2023.csv',\n",
       " '02-13-2020.csv',\n",
       " '02-13-2021.csv',\n",
       " '02-13-2022.csv',\n",
       " '02-13-2023.csv',\n",
       " '02-14-2020.csv',\n",
       " '02-14-2021.csv',\n",
       " '02-14-2022.csv',\n",
       " '02-14-2023.csv',\n",
       " '02-15-2020.csv',\n",
       " '02-15-2021.csv',\n",
       " '02-15-2022.csv',\n",
       " '02-15-2023.csv',\n",
       " '02-16-2020.csv',\n",
       " '02-16-2021.csv',\n",
       " '02-16-2022.csv',\n",
       " '02-16-2023.csv',\n",
       " '02-17-2020.csv',\n",
       " '02-17-2021.csv',\n",
       " '02-17-2022.csv',\n",
       " '02-17-2023.csv',\n",
       " '02-18-2020.csv',\n",
       " '02-18-2021.csv',\n",
       " '02-18-2022.csv',\n",
       " '02-18-2023.csv',\n",
       " '02-19-2020.csv',\n",
       " '02-19-2021.csv',\n",
       " '02-19-2022.csv',\n",
       " '02-19-2023.csv',\n",
       " '02-20-2020.csv',\n",
       " '02-20-2021.csv',\n",
       " '02-20-2022.csv',\n",
       " '02-20-2023.csv',\n",
       " '02-21-2020.csv',\n",
       " '02-21-2021.csv',\n",
       " '02-21-2022.csv',\n",
       " '02-21-2023.csv',\n",
       " '02-22-2020.csv',\n",
       " '02-22-2021.csv',\n",
       " '02-22-2022.csv',\n",
       " '02-22-2023.csv',\n",
       " '02-23-2020.csv',\n",
       " '02-23-2021.csv',\n",
       " '02-23-2022.csv',\n",
       " '02-23-2023.csv',\n",
       " '02-24-2020.csv',\n",
       " '02-24-2021.csv',\n",
       " '02-24-2022.csv',\n",
       " '02-24-2023.csv',\n",
       " '02-25-2020.csv',\n",
       " '02-25-2021.csv',\n",
       " '02-25-2022.csv',\n",
       " '02-25-2023.csv',\n",
       " '02-26-2020.csv',\n",
       " '02-26-2021.csv',\n",
       " '02-26-2022.csv',\n",
       " '02-26-2023.csv',\n",
       " '02-27-2020.csv',\n",
       " '02-27-2021.csv',\n",
       " '02-27-2022.csv',\n",
       " '02-27-2023.csv',\n",
       " '02-28-2020.csv',\n",
       " '02-28-2021.csv',\n",
       " '02-28-2022.csv',\n",
       " '02-28-2023.csv',\n",
       " '02-29-2020.csv',\n",
       " '03-01-2020.csv',\n",
       " '03-01-2021.csv',\n",
       " '03-01-2022.csv',\n",
       " '03-01-2023.csv',\n",
       " '03-02-2020.csv',\n",
       " '03-02-2021.csv',\n",
       " '03-02-2022.csv',\n",
       " '03-02-2023.csv',\n",
       " '03-03-2020.csv',\n",
       " '03-03-2021.csv',\n",
       " '03-03-2022.csv',\n",
       " '03-03-2023.csv',\n",
       " '03-04-2020.csv',\n",
       " '03-04-2021.csv',\n",
       " '03-04-2022.csv',\n",
       " '03-04-2023.csv',\n",
       " '03-05-2020.csv',\n",
       " '03-05-2021.csv',\n",
       " '03-05-2022.csv',\n",
       " '03-05-2023.csv',\n",
       " '03-06-2020.csv',\n",
       " '03-06-2021.csv',\n",
       " '03-06-2022.csv',\n",
       " '03-06-2023.csv',\n",
       " '03-07-2020.csv',\n",
       " '03-07-2021.csv',\n",
       " '03-07-2022.csv',\n",
       " '03-07-2023.csv',\n",
       " '03-08-2020.csv',\n",
       " '03-08-2021.csv',\n",
       " '03-08-2022.csv',\n",
       " '03-08-2023.csv',\n",
       " '03-09-2020.csv',\n",
       " '03-09-2021.csv',\n",
       " '03-09-2022.csv',\n",
       " '03-09-2023.csv',\n",
       " '03-10-2020.csv',\n",
       " '03-10-2021.csv',\n",
       " '03-10-2022.csv',\n",
       " '03-11-2020.csv',\n",
       " '03-11-2021.csv',\n",
       " '03-11-2022.csv',\n",
       " '03-12-2020.csv',\n",
       " '03-12-2021.csv',\n",
       " '03-12-2022.csv',\n",
       " '03-13-2020.csv',\n",
       " '03-13-2021.csv',\n",
       " '03-13-2022.csv',\n",
       " '03-14-2020.csv',\n",
       " '03-14-2021.csv',\n",
       " '03-14-2022.csv',\n",
       " '03-15-2020.csv',\n",
       " '03-15-2021.csv',\n",
       " '03-15-2022.csv',\n",
       " '03-16-2020.csv',\n",
       " '03-16-2021.csv',\n",
       " '03-16-2022.csv',\n",
       " '03-17-2020.csv',\n",
       " '03-17-2021.csv',\n",
       " '03-17-2022.csv',\n",
       " '03-18-2020.csv',\n",
       " '03-18-2021.csv',\n",
       " '03-18-2022.csv',\n",
       " '03-19-2020.csv',\n",
       " '03-19-2021.csv',\n",
       " '03-19-2022.csv',\n",
       " '03-20-2020.csv',\n",
       " '03-20-2021.csv',\n",
       " '03-20-2022.csv',\n",
       " '03-21-2020.csv',\n",
       " '03-21-2021.csv',\n",
       " '03-21-2022.csv',\n",
       " '03-22-2020.csv',\n",
       " '03-22-2021.csv',\n",
       " '03-22-2022.csv',\n",
       " '03-23-2020.csv',\n",
       " '03-23-2021.csv',\n",
       " '03-23-2022.csv',\n",
       " '03-24-2020.csv',\n",
       " '03-24-2021.csv',\n",
       " '03-24-2022.csv',\n",
       " '03-25-2020.csv',\n",
       " '03-25-2021.csv',\n",
       " '03-25-2022.csv',\n",
       " '03-26-2020.csv',\n",
       " '03-26-2021.csv',\n",
       " '03-26-2022.csv',\n",
       " '03-27-2020.csv',\n",
       " '03-27-2021.csv',\n",
       " '03-27-2022.csv',\n",
       " '03-28-2020.csv',\n",
       " '03-28-2021.csv',\n",
       " '03-28-2022.csv',\n",
       " '03-29-2020.csv',\n",
       " '03-29-2021.csv',\n",
       " '03-29-2022.csv',\n",
       " '03-30-2020.csv',\n",
       " '03-30-2021.csv',\n",
       " '03-30-2022.csv',\n",
       " '03-31-2020.csv',\n",
       " '03-31-2021.csv',\n",
       " '03-31-2022.csv',\n",
       " '04-01-2020.csv',\n",
       " '04-01-2021.csv',\n",
       " '04-01-2022.csv',\n",
       " '04-02-2020.csv',\n",
       " '04-02-2021.csv',\n",
       " '04-02-2022.csv',\n",
       " '04-03-2020.csv',\n",
       " '04-03-2021.csv',\n",
       " '04-03-2022.csv',\n",
       " '04-04-2020.csv',\n",
       " '04-04-2021.csv',\n",
       " '04-04-2022.csv',\n",
       " '04-05-2020.csv',\n",
       " '04-05-2021.csv',\n",
       " '04-05-2022.csv',\n",
       " '04-06-2020.csv',\n",
       " '04-06-2021.csv',\n",
       " '04-06-2022.csv',\n",
       " '04-07-2020.csv',\n",
       " '04-07-2021.csv',\n",
       " '04-07-2022.csv',\n",
       " '04-08-2020.csv',\n",
       " '04-08-2021.csv',\n",
       " '04-08-2022.csv',\n",
       " '04-09-2020.csv',\n",
       " '04-09-2021.csv',\n",
       " '04-09-2022.csv',\n",
       " '04-10-2020.csv',\n",
       " '04-10-2021.csv',\n",
       " '04-10-2022.csv',\n",
       " '04-11-2020.csv',\n",
       " '04-11-2021.csv',\n",
       " '04-11-2022.csv',\n",
       " '04-12-2020.csv',\n",
       " '04-12-2021.csv',\n",
       " '04-12-2022.csv',\n",
       " '04-13-2020.csv',\n",
       " '04-13-2021.csv',\n",
       " '04-13-2022.csv',\n",
       " '04-14-2020.csv',\n",
       " '04-14-2021.csv',\n",
       " '04-14-2022.csv',\n",
       " '04-15-2020.csv',\n",
       " '04-15-2021.csv',\n",
       " '04-15-2022.csv',\n",
       " '04-16-2020.csv',\n",
       " '04-16-2021.csv',\n",
       " '04-16-2022.csv',\n",
       " '04-17-2020.csv',\n",
       " '04-17-2021.csv',\n",
       " '04-17-2022.csv',\n",
       " '04-18-2020.csv',\n",
       " '04-18-2021.csv',\n",
       " '04-18-2022.csv',\n",
       " '04-19-2020.csv',\n",
       " '04-19-2021.csv',\n",
       " '04-19-2022.csv',\n",
       " '04-20-2020.csv',\n",
       " '04-20-2021.csv',\n",
       " '04-20-2022.csv',\n",
       " '04-21-2020.csv',\n",
       " '04-21-2021.csv',\n",
       " '04-21-2022.csv',\n",
       " '04-22-2020.csv',\n",
       " '04-22-2021.csv',\n",
       " '04-22-2022.csv',\n",
       " '04-23-2020.csv',\n",
       " '04-23-2021.csv',\n",
       " '04-23-2022.csv',\n",
       " '04-24-2020.csv',\n",
       " '04-24-2021.csv',\n",
       " '04-24-2022.csv',\n",
       " '04-25-2020.csv',\n",
       " '04-25-2021.csv',\n",
       " '04-25-2022.csv',\n",
       " '04-26-2020.csv',\n",
       " '04-26-2021.csv',\n",
       " '04-26-2022.csv',\n",
       " '04-27-2020.csv',\n",
       " '04-27-2021.csv',\n",
       " '04-27-2022.csv',\n",
       " '04-28-2020.csv',\n",
       " '04-28-2021.csv',\n",
       " '04-28-2022.csv',\n",
       " '04-29-2020.csv',\n",
       " '04-29-2021.csv',\n",
       " '04-29-2022.csv',\n",
       " '04-30-2020.csv',\n",
       " '04-30-2021.csv',\n",
       " '04-30-2022.csv',\n",
       " '05-01-2020.csv',\n",
       " '05-01-2021.csv',\n",
       " '05-01-2022.csv',\n",
       " '05-02-2020.csv',\n",
       " '05-02-2021.csv',\n",
       " '05-02-2022.csv',\n",
       " '05-03-2020.csv',\n",
       " '05-03-2021.csv',\n",
       " '05-03-2022.csv',\n",
       " '05-04-2020.csv',\n",
       " '05-04-2021.csv',\n",
       " '05-04-2022.csv',\n",
       " '05-05-2020.csv',\n",
       " '05-05-2021.csv',\n",
       " '05-05-2022.csv',\n",
       " '05-06-2020.csv',\n",
       " '05-06-2021.csv',\n",
       " '05-06-2022.csv',\n",
       " '05-07-2020.csv',\n",
       " '05-07-2021.csv',\n",
       " '05-07-2022.csv',\n",
       " '05-08-2020.csv',\n",
       " '05-08-2021.csv',\n",
       " '05-08-2022.csv',\n",
       " '05-09-2020.csv',\n",
       " '05-09-2021.csv',\n",
       " '05-09-2022.csv',\n",
       " '05-10-2020.csv',\n",
       " '05-10-2021.csv',\n",
       " '05-10-2022.csv',\n",
       " '05-11-2020.csv',\n",
       " '05-11-2021.csv',\n",
       " '05-11-2022.csv',\n",
       " '05-12-2020.csv',\n",
       " '05-12-2021.csv',\n",
       " '05-12-2022.csv',\n",
       " '05-13-2020.csv',\n",
       " '05-13-2021.csv',\n",
       " '05-13-2022.csv',\n",
       " '05-14-2020.csv',\n",
       " '05-14-2021.csv',\n",
       " '05-14-2022.csv',\n",
       " '05-15-2020.csv',\n",
       " '05-15-2021.csv',\n",
       " '05-15-2022.csv',\n",
       " '05-16-2020.csv',\n",
       " '05-16-2021.csv',\n",
       " '05-16-2022.csv',\n",
       " '05-17-2020.csv',\n",
       " '05-17-2021.csv',\n",
       " '05-17-2022.csv',\n",
       " '05-18-2020.csv',\n",
       " '05-18-2021.csv',\n",
       " '05-18-2022.csv',\n",
       " '05-19-2020.csv',\n",
       " '05-19-2021.csv',\n",
       " '05-19-2022.csv',\n",
       " '05-20-2020.csv',\n",
       " '05-20-2021.csv',\n",
       " '05-20-2022.csv',\n",
       " '05-21-2020.csv',\n",
       " '05-21-2021.csv',\n",
       " '05-21-2022.csv',\n",
       " '05-22-2020.csv',\n",
       " '05-22-2021.csv',\n",
       " '05-22-2022.csv',\n",
       " '05-23-2020.csv',\n",
       " '05-23-2021.csv',\n",
       " '05-23-2022.csv',\n",
       " '05-24-2020.csv',\n",
       " '05-24-2021.csv',\n",
       " '05-24-2022.csv',\n",
       " '05-25-2020.csv',\n",
       " '05-25-2021.csv',\n",
       " '05-25-2022.csv',\n",
       " '05-26-2020.csv',\n",
       " '05-26-2021.csv',\n",
       " '05-26-2022.csv',\n",
       " '05-27-2020.csv',\n",
       " '05-27-2021.csv',\n",
       " '05-27-2022.csv',\n",
       " '05-28-2020.csv',\n",
       " '05-28-2021.csv',\n",
       " '05-28-2022.csv',\n",
       " '05-29-2020.csv',\n",
       " '05-29-2021.csv',\n",
       " '05-29-2022.csv',\n",
       " '05-30-2020.csv',\n",
       " '05-30-2021.csv',\n",
       " '05-30-2022.csv',\n",
       " '05-31-2020.csv',\n",
       " '05-31-2021.csv',\n",
       " '05-31-2022.csv',\n",
       " '06-01-2020.csv',\n",
       " '06-01-2021.csv',\n",
       " '06-01-2022.csv',\n",
       " '06-02-2020.csv',\n",
       " '06-02-2021.csv',\n",
       " '06-02-2022.csv',\n",
       " '06-03-2020.csv',\n",
       " '06-03-2021.csv',\n",
       " '06-03-2022.csv',\n",
       " '06-04-2020.csv',\n",
       " '06-04-2021.csv',\n",
       " '06-04-2022.csv',\n",
       " '06-05-2020.csv',\n",
       " '06-05-2021.csv',\n",
       " '06-05-2022.csv',\n",
       " '06-06-2020.csv',\n",
       " '06-06-2021.csv',\n",
       " '06-06-2022.csv',\n",
       " '06-07-2020.csv',\n",
       " '06-07-2021.csv',\n",
       " '06-07-2022.csv',\n",
       " '06-08-2020.csv',\n",
       " '06-08-2021.csv',\n",
       " '06-08-2022.csv',\n",
       " '06-09-2020.csv',\n",
       " '06-09-2021.csv',\n",
       " '06-09-2022.csv',\n",
       " '06-10-2020.csv',\n",
       " '06-10-2021.csv',\n",
       " '06-10-2022.csv',\n",
       " '06-11-2020.csv',\n",
       " '06-11-2021.csv',\n",
       " '06-11-2022.csv',\n",
       " '06-12-2020.csv',\n",
       " '06-12-2021.csv',\n",
       " '06-12-2022.csv',\n",
       " '06-13-2020.csv',\n",
       " '06-13-2021.csv',\n",
       " '06-13-2022.csv',\n",
       " '06-14-2020.csv',\n",
       " '06-14-2021.csv',\n",
       " '06-14-2022.csv',\n",
       " '06-15-2020.csv',\n",
       " '06-15-2021.csv',\n",
       " '06-15-2022.csv',\n",
       " '06-16-2020.csv',\n",
       " '06-16-2021.csv',\n",
       " '06-16-2022.csv',\n",
       " '06-17-2020.csv',\n",
       " '06-17-2021.csv',\n",
       " '06-17-2022.csv',\n",
       " '06-18-2020.csv',\n",
       " '06-18-2021.csv',\n",
       " '06-18-2022.csv',\n",
       " '06-19-2020.csv',\n",
       " '06-19-2021.csv',\n",
       " '06-19-2022.csv',\n",
       " '06-20-2020.csv',\n",
       " '06-20-2021.csv',\n",
       " '06-20-2022.csv',\n",
       " '06-21-2020.csv',\n",
       " '06-21-2021.csv',\n",
       " '06-21-2022.csv',\n",
       " '06-22-2020.csv',\n",
       " '06-22-2021.csv',\n",
       " '06-22-2022.csv',\n",
       " '06-23-2020.csv',\n",
       " '06-23-2021.csv',\n",
       " '06-23-2022.csv',\n",
       " '06-24-2020.csv',\n",
       " '06-24-2021.csv',\n",
       " '06-24-2022.csv',\n",
       " '06-25-2020.csv',\n",
       " '06-25-2021.csv',\n",
       " '06-25-2022.csv',\n",
       " '06-26-2020.csv',\n",
       " '06-26-2021.csv',\n",
       " '06-26-2022.csv',\n",
       " '06-27-2020.csv',\n",
       " '06-27-2021.csv',\n",
       " '06-27-2022.csv',\n",
       " '06-28-2020.csv',\n",
       " '06-28-2021.csv',\n",
       " '06-28-2022.csv',\n",
       " '06-29-2020.csv',\n",
       " '06-29-2021.csv',\n",
       " '06-29-2022.csv',\n",
       " '06-30-2020.csv',\n",
       " '06-30-2021.csv',\n",
       " '06-30-2022.csv',\n",
       " '07-01-2020.csv',\n",
       " '07-01-2021.csv',\n",
       " '07-01-2022.csv',\n",
       " '07-02-2020.csv',\n",
       " '07-02-2021.csv',\n",
       " '07-02-2022.csv',\n",
       " '07-03-2020.csv',\n",
       " '07-03-2021.csv',\n",
       " '07-03-2022.csv',\n",
       " '07-04-2020.csv',\n",
       " '07-04-2021.csv',\n",
       " '07-04-2022.csv',\n",
       " '07-05-2020.csv',\n",
       " '07-05-2021.csv',\n",
       " '07-05-2022.csv',\n",
       " '07-06-2020.csv',\n",
       " '07-06-2021.csv',\n",
       " '07-06-2022.csv',\n",
       " '07-07-2020.csv',\n",
       " '07-07-2021.csv',\n",
       " '07-07-2022.csv',\n",
       " '07-08-2020.csv',\n",
       " '07-08-2021.csv',\n",
       " '07-08-2022.csv',\n",
       " '07-09-2020.csv',\n",
       " '07-09-2021.csv',\n",
       " '07-09-2022.csv',\n",
       " '07-10-2020.csv',\n",
       " '07-10-2021.csv',\n",
       " '07-10-2022.csv',\n",
       " '07-11-2020.csv',\n",
       " '07-11-2021.csv',\n",
       " '07-11-2022.csv',\n",
       " '07-12-2020.csv',\n",
       " '07-12-2021.csv',\n",
       " '07-12-2022.csv',\n",
       " '07-13-2020.csv',\n",
       " '07-13-2021.csv',\n",
       " '07-13-2022.csv',\n",
       " '07-14-2020.csv',\n",
       " '07-14-2021.csv',\n",
       " '07-14-2022.csv',\n",
       " '07-15-2020.csv',\n",
       " '07-15-2021.csv',\n",
       " '07-15-2022.csv',\n",
       " '07-16-2020.csv',\n",
       " '07-16-2021.csv',\n",
       " '07-16-2022.csv',\n",
       " '07-17-2020.csv',\n",
       " '07-17-2021.csv',\n",
       " '07-17-2022.csv',\n",
       " '07-18-2020.csv',\n",
       " '07-18-2021.csv',\n",
       " '07-18-2022.csv',\n",
       " '07-19-2020.csv',\n",
       " '07-19-2021.csv',\n",
       " '07-19-2022.csv',\n",
       " '07-20-2020.csv',\n",
       " '07-20-2021.csv',\n",
       " '07-20-2022.csv',\n",
       " '07-21-2020.csv',\n",
       " '07-21-2021.csv',\n",
       " '07-21-2022.csv',\n",
       " '07-22-2020.csv',\n",
       " '07-22-2021.csv',\n",
       " '07-22-2022.csv',\n",
       " '07-23-2020.csv',\n",
       " '07-23-2021.csv',\n",
       " '07-23-2022.csv',\n",
       " '07-24-2020.csv',\n",
       " '07-24-2021.csv',\n",
       " '07-24-2022.csv',\n",
       " '07-25-2020.csv',\n",
       " '07-25-2021.csv',\n",
       " '07-25-2022.csv',\n",
       " '07-26-2020.csv',\n",
       " '07-26-2021.csv',\n",
       " '07-26-2022.csv',\n",
       " '07-27-2020.csv',\n",
       " '07-27-2021.csv',\n",
       " '07-27-2022.csv',\n",
       " '07-28-2020.csv',\n",
       " '07-28-2021.csv',\n",
       " '07-28-2022.csv',\n",
       " '07-29-2020.csv',\n",
       " '07-29-2021.csv',\n",
       " '07-29-2022.csv',\n",
       " '07-30-2020.csv',\n",
       " '07-30-2021.csv',\n",
       " '07-30-2022.csv',\n",
       " '07-31-2020.csv',\n",
       " '07-31-2021.csv',\n",
       " '07-31-2022.csv',\n",
       " '08-01-2020.csv',\n",
       " '08-01-2021.csv',\n",
       " '08-01-2022.csv',\n",
       " '08-02-2020.csv',\n",
       " '08-02-2021.csv',\n",
       " '08-02-2022.csv',\n",
       " '08-03-2020.csv',\n",
       " '08-03-2021.csv',\n",
       " '08-03-2022.csv',\n",
       " '08-04-2020.csv',\n",
       " '08-04-2021.csv',\n",
       " '08-04-2022.csv',\n",
       " '08-05-2020.csv',\n",
       " '08-05-2021.csv',\n",
       " '08-05-2022.csv',\n",
       " '08-06-2020.csv',\n",
       " '08-06-2021.csv',\n",
       " '08-06-2022.csv',\n",
       " '08-07-2020.csv',\n",
       " '08-07-2021.csv',\n",
       " '08-07-2022.csv',\n",
       " '08-08-2020.csv',\n",
       " '08-08-2021.csv',\n",
       " '08-08-2022.csv',\n",
       " '08-09-2020.csv',\n",
       " '08-09-2021.csv',\n",
       " '08-09-2022.csv',\n",
       " '08-10-2020.csv',\n",
       " '08-10-2021.csv',\n",
       " '08-10-2022.csv',\n",
       " '08-11-2020.csv',\n",
       " '08-11-2021.csv',\n",
       " '08-11-2022.csv',\n",
       " '08-12-2020.csv',\n",
       " '08-12-2021.csv',\n",
       " '08-12-2022.csv',\n",
       " '08-13-2020.csv',\n",
       " '08-13-2021.csv',\n",
       " '08-13-2022.csv',\n",
       " '08-14-2020.csv',\n",
       " '08-14-2021.csv',\n",
       " '08-14-2022.csv',\n",
       " '08-15-2020.csv',\n",
       " '08-15-2021.csv',\n",
       " '08-15-2022.csv',\n",
       " '08-16-2020.csv',\n",
       " '08-16-2021.csv',\n",
       " '08-16-2022.csv',\n",
       " '08-17-2020.csv',\n",
       " '08-17-2021.csv',\n",
       " '08-17-2022.csv',\n",
       " '08-18-2020.csv',\n",
       " '08-18-2021.csv',\n",
       " '08-18-2022.csv',\n",
       " '08-19-2020.csv',\n",
       " '08-19-2021.csv',\n",
       " '08-19-2022.csv',\n",
       " '08-20-2020.csv',\n",
       " '08-20-2021.csv',\n",
       " '08-20-2022.csv',\n",
       " '08-21-2020.csv',\n",
       " '08-21-2021.csv',\n",
       " '08-21-2022.csv',\n",
       " '08-22-2020.csv',\n",
       " '08-22-2021.csv',\n",
       " '08-22-2022.csv',\n",
       " '08-23-2020.csv',\n",
       " '08-23-2021.csv',\n",
       " '08-23-2022.csv',\n",
       " '08-24-2020.csv',\n",
       " '08-24-2021.csv',\n",
       " '08-24-2022.csv',\n",
       " '08-25-2020.csv',\n",
       " '08-25-2021.csv',\n",
       " '08-25-2022.csv',\n",
       " '08-26-2020.csv',\n",
       " '08-26-2021.csv',\n",
       " '08-26-2022.csv',\n",
       " '08-27-2020.csv',\n",
       " '08-27-2021.csv',\n",
       " '08-27-2022.csv',\n",
       " '08-28-2020.csv',\n",
       " '08-28-2021.csv',\n",
       " '08-28-2022.csv',\n",
       " '08-29-2020.csv',\n",
       " '08-29-2021.csv',\n",
       " '08-29-2022.csv',\n",
       " '08-30-2020.csv',\n",
       " '08-30-2021.csv',\n",
       " '08-30-2022.csv',\n",
       " '08-31-2020.csv',\n",
       " '08-31-2021.csv',\n",
       " '08-31-2022.csv',\n",
       " '09-01-2020.csv',\n",
       " '09-01-2021.csv',\n",
       " '09-01-2022.csv',\n",
       " '09-02-2020.csv',\n",
       " '09-02-2021.csv',\n",
       " '09-02-2022.csv',\n",
       " '09-03-2020.csv',\n",
       " '09-03-2021.csv',\n",
       " '09-03-2022.csv',\n",
       " '09-04-2020.csv',\n",
       " '09-04-2021.csv',\n",
       " '09-04-2022.csv',\n",
       " '09-05-2020.csv',\n",
       " '09-05-2021.csv',\n",
       " '09-05-2022.csv',\n",
       " '09-06-2020.csv',\n",
       " '09-06-2021.csv',\n",
       " '09-06-2022.csv',\n",
       " '09-07-2020.csv',\n",
       " '09-07-2021.csv',\n",
       " '09-07-2022.csv',\n",
       " '09-08-2020.csv',\n",
       " '09-08-2021.csv',\n",
       " '09-08-2022.csv',\n",
       " '09-09-2020.csv',\n",
       " '09-09-2021.csv',\n",
       " '09-09-2022.csv',\n",
       " '09-10-2020.csv',\n",
       " '09-10-2021.csv',\n",
       " '09-10-2022.csv',\n",
       " '09-11-2020.csv',\n",
       " '09-11-2021.csv',\n",
       " '09-11-2022.csv',\n",
       " '09-12-2020.csv',\n",
       " '09-12-2021.csv',\n",
       " '09-12-2022.csv',\n",
       " '09-13-2020.csv',\n",
       " '09-13-2021.csv',\n",
       " '09-13-2022.csv',\n",
       " '09-14-2020.csv',\n",
       " '09-14-2021.csv',\n",
       " '09-14-2022.csv',\n",
       " '09-15-2020.csv',\n",
       " '09-15-2021.csv',\n",
       " '09-15-2022.csv',\n",
       " '09-16-2020.csv',\n",
       " '09-16-2021.csv',\n",
       " '09-16-2022.csv',\n",
       " '09-17-2020.csv',\n",
       " '09-17-2021.csv',\n",
       " '09-17-2022.csv',\n",
       " '09-18-2020.csv',\n",
       " '09-18-2021.csv',\n",
       " '09-18-2022.csv',\n",
       " '09-19-2020.csv',\n",
       " '09-19-2021.csv',\n",
       " '09-19-2022.csv',\n",
       " '09-20-2020.csv',\n",
       " '09-20-2021.csv',\n",
       " '09-20-2022.csv',\n",
       " '09-21-2020.csv',\n",
       " '09-21-2021.csv',\n",
       " '09-21-2022.csv',\n",
       " '09-22-2020.csv',\n",
       " '09-22-2021.csv',\n",
       " '09-22-2022.csv',\n",
       " '09-23-2020.csv',\n",
       " '09-23-2021.csv',\n",
       " '09-23-2022.csv',\n",
       " '09-24-2020.csv',\n",
       " '09-24-2021.csv',\n",
       " '09-24-2022.csv',\n",
       " '09-25-2020.csv',\n",
       " '09-25-2021.csv',\n",
       " '09-25-2022.csv',\n",
       " '09-26-2020.csv',\n",
       " '09-26-2021.csv',\n",
       " '09-26-2022.csv',\n",
       " '09-27-2020.csv',\n",
       " '09-27-2021.csv',\n",
       " '09-27-2022.csv',\n",
       " '09-28-2020.csv',\n",
       " '09-28-2021.csv',\n",
       " '09-28-2022.csv',\n",
       " '09-29-2020.csv',\n",
       " '09-29-2021.csv',\n",
       " '09-29-2022.csv',\n",
       " '09-30-2020.csv',\n",
       " '09-30-2021.csv',\n",
       " '09-30-2022.csv',\n",
       " '10-01-2020.csv',\n",
       " '10-01-2021.csv',\n",
       " '10-01-2022.csv',\n",
       " '10-02-2020.csv',\n",
       " '10-02-2021.csv',\n",
       " '10-02-2022.csv',\n",
       " '10-03-2020.csv',\n",
       " '10-03-2021.csv',\n",
       " '10-03-2022.csv',\n",
       " '10-04-2020.csv',\n",
       " '10-04-2021.csv',\n",
       " '10-04-2022.csv',\n",
       " '10-05-2020.csv',\n",
       " '10-05-2021.csv',\n",
       " '10-05-2022.csv',\n",
       " '10-06-2020.csv',\n",
       " '10-06-2021.csv',\n",
       " '10-06-2022.csv',\n",
       " '10-07-2020.csv',\n",
       " '10-07-2021.csv',\n",
       " '10-07-2022.csv',\n",
       " '10-08-2020.csv',\n",
       " '10-08-2021.csv',\n",
       " '10-08-2022.csv',\n",
       " '10-09-2020.csv',\n",
       " '10-09-2021.csv',\n",
       " '10-09-2022.csv',\n",
       " '10-10-2020.csv',\n",
       " '10-10-2021.csv',\n",
       " '10-10-2022.csv',\n",
       " '10-11-2020.csv',\n",
       " '10-11-2021.csv',\n",
       " '10-11-2022.csv',\n",
       " '10-12-2020.csv',\n",
       " '10-12-2021.csv',\n",
       " '10-12-2022.csv',\n",
       " '10-13-2020.csv',\n",
       " '10-13-2021.csv',\n",
       " '10-13-2022.csv',\n",
       " '10-14-2020.csv',\n",
       " '10-14-2021.csv',\n",
       " '10-14-2022.csv',\n",
       " '10-15-2020.csv',\n",
       " '10-15-2021.csv',\n",
       " '10-15-2022.csv',\n",
       " '10-16-2020.csv',\n",
       " '10-16-2021.csv',\n",
       " '10-16-2022.csv',\n",
       " '10-17-2020.csv',\n",
       " '10-17-2021.csv',\n",
       " '10-17-2022.csv',\n",
       " '10-18-2020.csv',\n",
       " '10-18-2021.csv',\n",
       " '10-18-2022.csv',\n",
       " '10-19-2020.csv',\n",
       " '10-19-2021.csv',\n",
       " '10-19-2022.csv',\n",
       " '10-20-2020.csv',\n",
       " '10-20-2021.csv',\n",
       " '10-20-2022.csv',\n",
       " '10-21-2020.csv',\n",
       " '10-21-2021.csv',\n",
       " '10-21-2022.csv',\n",
       " '10-22-2020.csv',\n",
       " '10-22-2021.csv',\n",
       " '10-22-2022.csv',\n",
       " '10-23-2020.csv',\n",
       " '10-23-2021.csv',\n",
       " '10-23-2022.csv',\n",
       " '10-24-2020.csv',\n",
       " '10-24-2021.csv',\n",
       " '10-24-2022.csv',\n",
       " '10-25-2020.csv',\n",
       " '10-25-2021.csv',\n",
       " '10-25-2022.csv',\n",
       " '10-26-2020.csv',\n",
       " '10-26-2021.csv',\n",
       " '10-26-2022.csv',\n",
       " '10-27-2020.csv',\n",
       " '10-27-2021.csv',\n",
       " '10-27-2022.csv',\n",
       " '10-28-2020.csv',\n",
       " '10-28-2021.csv',\n",
       " '10-28-2022.csv',\n",
       " '10-29-2020.csv',\n",
       " '10-29-2021.csv',\n",
       " '10-29-2022.csv',\n",
       " '10-30-2020.csv',\n",
       " '10-30-2021.csv',\n",
       " '10-30-2022.csv',\n",
       " '10-31-2020.csv',\n",
       " '10-31-2021.csv',\n",
       " '10-31-2022.csv',\n",
       " '11-01-2020.csv',\n",
       " '11-01-2021.csv',\n",
       " '11-01-2022.csv',\n",
       " '11-02-2020.csv',\n",
       " '11-02-2021.csv',\n",
       " '11-02-2022.csv',\n",
       " '11-03-2020.csv',\n",
       " '11-03-2021.csv',\n",
       " '11-03-2022.csv',\n",
       " '11-04-2020.csv',\n",
       " '11-04-2021.csv',\n",
       " '11-04-2022.csv',\n",
       " '11-05-2020.csv',\n",
       " '11-05-2021.csv',\n",
       " '11-05-2022.csv',\n",
       " '11-06-2020.csv',\n",
       " '11-06-2021.csv',\n",
       " '11-06-2022.csv',\n",
       " '11-07-2020.csv',\n",
       " '11-07-2021.csv',\n",
       " '11-07-2022.csv',\n",
       " '11-08-2020.csv',\n",
       " '11-08-2021.csv',\n",
       " '11-08-2022.csv',\n",
       " '11-09-2020.csv',\n",
       " '11-09-2021.csv',\n",
       " '11-09-2022.csv',\n",
       " '11-10-2020.csv',\n",
       " '11-10-2021.csv',\n",
       " '11-10-2022.csv',\n",
       " '11-11-2020.csv',\n",
       " '11-11-2021.csv',\n",
       " '11-11-2022.csv',\n",
       " '11-12-2020.csv',\n",
       " '11-12-2021.csv',\n",
       " '11-12-2022.csv',\n",
       " '11-13-2020.csv',\n",
       " '11-13-2021.csv',\n",
       " '11-13-2022.csv',\n",
       " '11-14-2020.csv',\n",
       " ...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list.sort()\n",
    "csv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543a78f",
   "metadata": {},
   "source": [
    "## total 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f25f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋팅\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# json파일 불러옹기\n",
    "with open('ex_datafile/COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "# 컬럼명 변경\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "\n",
    "# csv파일 읽기고 전처리\n",
    "def create_dateframe(filename):\n",
    "    file_path = 'ex_datafile/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "    csv = pd.read_csv(file_path + filename,encoding='utf-8')                   # 1.\n",
    "    try : \n",
    "        csv = csv[['Province_State', 'Country_Region', 'Confirmed']]           # 2.\n",
    "\n",
    "    except:\n",
    "        csv = csv[['Province/State', 'Country/Region', 'Confirmed']]           # 2.\n",
    "        csv.columns = ['Province_State', 'Country_Region', 'Confirmed'] \n",
    "\n",
    "    csv = csv.dropna(subset=['Confirmed'])                                     # 3.\n",
    "    csv['Country_Region'] = csv.apply(country_name_convert, axis=1)            # 4.\n",
    "    csv = csv.astype({'Confirmed' : 'int64'})                                  # 5.\n",
    "    csv = csv[['Country_Region', 'Confirmed']].groupby('Country_Region').sum() # 6.\n",
    "    \n",
    "    date_column = filename.split('.')[0].lstrip('0').replace('-','/')          # 7.\n",
    "    csv.columns = [date_column]\n",
    "    return csv\n",
    "\n",
    "def generate_dateframe_by_path(file_path):\n",
    "\n",
    "    file_list, csv_list = os.listdir(file_path), list()\n",
    "    first_doc = True\n",
    "    for file in file_list:\n",
    "        if file.split(\".\")[-1] == 'csv':\n",
    "            csv_list.append(file)\n",
    "    csv_list.sort()\n",
    "    \n",
    "    for file in csv_list:\n",
    "        doc = create_dateframe(file)\n",
    "        if first_doc:\n",
    "            final_doc, first_doc = doc, False\n",
    "        else:\n",
    "            final_doc = pd.merge(final_doc, doc, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    final_doc = final_doc.fillna(0)\n",
    "    return final_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8e566c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/01/2021</th>\n",
       "      <th>1/01/2022</th>\n",
       "      <th>1/01/2023</th>\n",
       "      <th>1/02/2021</th>\n",
       "      <th>1/02/2022</th>\n",
       "      <th>1/02/2023</th>\n",
       "      <th>1/03/2021</th>\n",
       "      <th>1/03/2022</th>\n",
       "      <th>1/03/2023</th>\n",
       "      <th>1/04/2021</th>\n",
       "      <th>...</th>\n",
       "      <th>12/28/2022</th>\n",
       "      <th>12/29/2020</th>\n",
       "      <th>12/29/2021</th>\n",
       "      <th>12/29/2022</th>\n",
       "      <th>12/30/2020</th>\n",
       "      <th>12/30/2021</th>\n",
       "      <th>12/30/2022</th>\n",
       "      <th>12/31/2020</th>\n",
       "      <th>12/31/2021</th>\n",
       "      <th>12/31/2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>52513.0</td>\n",
       "      <td>158107.0</td>\n",
       "      <td>207616.0</td>\n",
       "      <td>52586.0</td>\n",
       "      <td>158189.0</td>\n",
       "      <td>207627.0</td>\n",
       "      <td>52709.0</td>\n",
       "      <td>158183.0</td>\n",
       "      <td>207654.0</td>\n",
       "      <td>52909.0</td>\n",
       "      <td>...</td>\n",
       "      <td>207493.0</td>\n",
       "      <td>52147.0</td>\n",
       "      <td>158037.0</td>\n",
       "      <td>207511.0</td>\n",
       "      <td>52330.0</td>\n",
       "      <td>158056.0</td>\n",
       "      <td>207550.0</td>\n",
       "      <td>52330.0</td>\n",
       "      <td>158084.0</td>\n",
       "      <td>207559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>58316.0</td>\n",
       "      <td>210224.0</td>\n",
       "      <td>333811.0</td>\n",
       "      <td>58991.0</td>\n",
       "      <td>210885.0</td>\n",
       "      <td>333812.0</td>\n",
       "      <td>59438.0</td>\n",
       "      <td>210885.0</td>\n",
       "      <td>333812.0</td>\n",
       "      <td>59623.0</td>\n",
       "      <td>...</td>\n",
       "      <td>333776.0</td>\n",
       "      <td>57146.0</td>\n",
       "      <td>208899.0</td>\n",
       "      <td>333776.0</td>\n",
       "      <td>57727.0</td>\n",
       "      <td>208899.0</td>\n",
       "      <td>333806.0</td>\n",
       "      <td>58316.0</td>\n",
       "      <td>210224.0</td>\n",
       "      <td>333806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>99897.0</td>\n",
       "      <td>218818.0</td>\n",
       "      <td>271229.0</td>\n",
       "      <td>100159.0</td>\n",
       "      <td>219159.0</td>\n",
       "      <td>271229.0</td>\n",
       "      <td>100408.0</td>\n",
       "      <td>219532.0</td>\n",
       "      <td>271230.0</td>\n",
       "      <td>100645.0</td>\n",
       "      <td>...</td>\n",
       "      <td>271208.0</td>\n",
       "      <td>98988.0</td>\n",
       "      <td>217647.0</td>\n",
       "      <td>271217.0</td>\n",
       "      <td>99311.0</td>\n",
       "      <td>218037.0</td>\n",
       "      <td>271223.0</td>\n",
       "      <td>99610.0</td>\n",
       "      <td>218432.0</td>\n",
       "      <td>271228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>8117.0</td>\n",
       "      <td>23740.0</td>\n",
       "      <td>47751.0</td>\n",
       "      <td>8166.0</td>\n",
       "      <td>23740.0</td>\n",
       "      <td>47751.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>24502.0</td>\n",
       "      <td>47751.0</td>\n",
       "      <td>8249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47751.0</td>\n",
       "      <td>7919.0</td>\n",
       "      <td>22823.0</td>\n",
       "      <td>47751.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>23122.0</td>\n",
       "      <td>47751.0</td>\n",
       "      <td>8049.0</td>\n",
       "      <td>23740.0</td>\n",
       "      <td>47751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>17568.0</td>\n",
       "      <td>82398.0</td>\n",
       "      <td>105095.0</td>\n",
       "      <td>17608.0</td>\n",
       "      <td>82920.0</td>\n",
       "      <td>105095.0</td>\n",
       "      <td>17642.0</td>\n",
       "      <td>83764.0</td>\n",
       "      <td>105095.0</td>\n",
       "      <td>17684.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105095.0</td>\n",
       "      <td>17371.0</td>\n",
       "      <td>78475.0</td>\n",
       "      <td>105095.0</td>\n",
       "      <td>17433.0</td>\n",
       "      <td>79871.0</td>\n",
       "      <td>105095.0</td>\n",
       "      <td>17553.0</td>\n",
       "      <td>81593.0</td>\n",
       "      <td>105095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>139223.0</td>\n",
       "      <td>469748.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>140287.0</td>\n",
       "      <td>469748.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>141219.0</td>\n",
       "      <td>469748.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>142228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>135459.0</td>\n",
       "      <td>469748.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>136736.0</td>\n",
       "      <td>469748.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>138004.0</td>\n",
       "      <td>469748.0</td>\n",
       "      <td>703228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter Olympics 2022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>2101.0</td>\n",
       "      <td>10127.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>10138.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>10125.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>10126.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>10126.0</td>\n",
       "      <td>11945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>20997.0</td>\n",
       "      <td>257948.0</td>\n",
       "      <td>334629.0</td>\n",
       "      <td>21230.0</td>\n",
       "      <td>259677.0</td>\n",
       "      <td>334661.0</td>\n",
       "      <td>21582.0</td>\n",
       "      <td>261221.0</td>\n",
       "      <td>334695.0</td>\n",
       "      <td>21993.0</td>\n",
       "      <td>...</td>\n",
       "      <td>334196.0</td>\n",
       "      <td>20177.0</td>\n",
       "      <td>243638.0</td>\n",
       "      <td>334294.0</td>\n",
       "      <td>20462.0</td>\n",
       "      <td>249193.0</td>\n",
       "      <td>334425.0</td>\n",
       "      <td>20725.0</td>\n",
       "      <td>254274.0</td>\n",
       "      <td>334425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>14084.0</td>\n",
       "      <td>214214.0</td>\n",
       "      <td>259981.0</td>\n",
       "      <td>14491.0</td>\n",
       "      <td>214214.0</td>\n",
       "      <td>259981.0</td>\n",
       "      <td>15265.0</td>\n",
       "      <td>216087.0</td>\n",
       "      <td>259981.0</td>\n",
       "      <td>15829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>259981.0</td>\n",
       "      <td>13325.0</td>\n",
       "      <td>207548.0</td>\n",
       "      <td>259981.0</td>\n",
       "      <td>13625.0</td>\n",
       "      <td>211728.0</td>\n",
       "      <td>259981.0</td>\n",
       "      <td>13867.0</td>\n",
       "      <td>213258.0</td>\n",
       "      <td>259981.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 1143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1/01/2021  1/01/2022  1/01/2023  1/02/2021  1/02/2022  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan             52513.0   158107.0   207616.0    52586.0   158189.0   \n",
       "Albania                 58316.0   210224.0   333811.0    58991.0   210885.0   \n",
       "Algeria                 99897.0   218818.0   271229.0   100159.0   219159.0   \n",
       "Andorra                  8117.0    23740.0    47751.0     8166.0    23740.0   \n",
       "Angola                  17568.0    82398.0   105095.0    17608.0    82920.0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza     139223.0   469748.0   703228.0   140287.0   469748.0   \n",
       "Winter Olympics 2022        0.0        0.0      535.0        0.0        0.0   \n",
       "Yemen                    2101.0    10127.0    11945.0     2101.0    10130.0   \n",
       "Zambia                  20997.0   257948.0   334629.0    21230.0   259677.0   \n",
       "Zimbabwe                14084.0   214214.0   259981.0    14491.0   214214.0   \n",
       "\n",
       "                      1/02/2023  1/03/2021  1/03/2022  1/03/2023  1/04/2021  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan            207627.0    52709.0   158183.0   207654.0    52909.0   \n",
       "Albania                333812.0    59438.0   210885.0   333812.0    59623.0   \n",
       "Algeria                271229.0   100408.0   219532.0   271230.0   100645.0   \n",
       "Andorra                 47751.0     8192.0    24502.0    47751.0     8249.0   \n",
       "Angola                 105095.0    17642.0    83764.0   105095.0    17684.0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza     703228.0   141219.0   469748.0   703228.0   142228.0   \n",
       "Winter Olympics 2022      535.0        0.0        0.0      535.0        0.0   \n",
       "Yemen                   11945.0     2101.0    10138.0    11945.0     2101.0   \n",
       "Zambia                 334661.0    21582.0   261221.0   334695.0    21993.0   \n",
       "Zimbabwe               259981.0    15265.0   216087.0   259981.0    15829.0   \n",
       "\n",
       "                      ...  12/28/2022  12/29/2020  12/29/2021  12/29/2022  \\\n",
       "Country_Region        ...                                                   \n",
       "Afghanistan           ...    207493.0     52147.0    158037.0    207511.0   \n",
       "Albania               ...    333776.0     57146.0    208899.0    333776.0   \n",
       "Algeria               ...    271208.0     98988.0    217647.0    271217.0   \n",
       "Andorra               ...     47751.0      7919.0     22823.0     47751.0   \n",
       "Angola                ...    105095.0     17371.0     78475.0    105095.0   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "West Bank and Gaza    ...    703228.0    135459.0    469748.0    703228.0   \n",
       "Winter Olympics 2022  ...       535.0         0.0         0.0       535.0   \n",
       "Yemen                 ...     11945.0      2096.0     10125.0     11945.0   \n",
       "Zambia                ...    334196.0     20177.0    243638.0    334294.0   \n",
       "Zimbabwe              ...    259981.0     13325.0    207548.0    259981.0   \n",
       "\n",
       "                      12/30/2020  12/30/2021  12/30/2022  12/31/2020  \\\n",
       "Country_Region                                                         \n",
       "Afghanistan              52330.0    158056.0    207550.0     52330.0   \n",
       "Albania                  57727.0    208899.0    333806.0     58316.0   \n",
       "Algeria                  99311.0    218037.0    271223.0     99610.0   \n",
       "Andorra                   7983.0     23122.0     47751.0      8049.0   \n",
       "Angola                   17433.0     79871.0    105095.0     17553.0   \n",
       "...                          ...         ...         ...         ...   \n",
       "West Bank and Gaza      136736.0    469748.0    703228.0    138004.0   \n",
       "Winter Olympics 2022         0.0         0.0       535.0         0.0   \n",
       "Yemen                     2097.0     10126.0     11945.0      2099.0   \n",
       "Zambia                   20462.0    249193.0    334425.0     20725.0   \n",
       "Zimbabwe                 13625.0    211728.0    259981.0     13867.0   \n",
       "\n",
       "                      12/31/2021  12/31/2022  \n",
       "Country_Region                                \n",
       "Afghanistan             158084.0    207559.0  \n",
       "Albania                 210224.0    333806.0  \n",
       "Algeria                 218432.0    271228.0  \n",
       "Andorra                  23740.0     47751.0  \n",
       "Angola                   81593.0    105095.0  \n",
       "...                          ...         ...  \n",
       "West Bank and Gaza      469748.0    703228.0  \n",
       "Winter Olympics 2022         0.0       535.0  \n",
       "Yemen                    10126.0     11945.0  \n",
       "Zambia                  254274.0    334425.0  \n",
       "Zimbabwe                213258.0    259981.0  \n",
       "\n",
       "[201 rows x 1143 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'ex_datafile/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "doc = generate_dateframe_by_path(file_path)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30fd553",
   "metadata": {},
   "source": [
    "#### 데이터 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14878570",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/01/2021</th>\n",
       "      <th>1/01/2022</th>\n",
       "      <th>1/01/2023</th>\n",
       "      <th>1/02/2021</th>\n",
       "      <th>1/02/2022</th>\n",
       "      <th>1/02/2023</th>\n",
       "      <th>1/03/2021</th>\n",
       "      <th>1/03/2022</th>\n",
       "      <th>1/03/2023</th>\n",
       "      <th>1/04/2021</th>\n",
       "      <th>...</th>\n",
       "      <th>12/28/2022</th>\n",
       "      <th>12/29/2020</th>\n",
       "      <th>12/29/2021</th>\n",
       "      <th>12/29/2022</th>\n",
       "      <th>12/30/2020</th>\n",
       "      <th>12/30/2021</th>\n",
       "      <th>12/30/2022</th>\n",
       "      <th>12/31/2020</th>\n",
       "      <th>12/31/2021</th>\n",
       "      <th>12/31/2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>52513</td>\n",
       "      <td>158107</td>\n",
       "      <td>207616</td>\n",
       "      <td>52586</td>\n",
       "      <td>158189</td>\n",
       "      <td>207627</td>\n",
       "      <td>52709</td>\n",
       "      <td>158183</td>\n",
       "      <td>207654</td>\n",
       "      <td>52909</td>\n",
       "      <td>...</td>\n",
       "      <td>207493</td>\n",
       "      <td>52147</td>\n",
       "      <td>158037</td>\n",
       "      <td>207511</td>\n",
       "      <td>52330</td>\n",
       "      <td>158056</td>\n",
       "      <td>207550</td>\n",
       "      <td>52330</td>\n",
       "      <td>158084</td>\n",
       "      <td>207559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>58316</td>\n",
       "      <td>210224</td>\n",
       "      <td>333811</td>\n",
       "      <td>58991</td>\n",
       "      <td>210885</td>\n",
       "      <td>333812</td>\n",
       "      <td>59438</td>\n",
       "      <td>210885</td>\n",
       "      <td>333812</td>\n",
       "      <td>59623</td>\n",
       "      <td>...</td>\n",
       "      <td>333776</td>\n",
       "      <td>57146</td>\n",
       "      <td>208899</td>\n",
       "      <td>333776</td>\n",
       "      <td>57727</td>\n",
       "      <td>208899</td>\n",
       "      <td>333806</td>\n",
       "      <td>58316</td>\n",
       "      <td>210224</td>\n",
       "      <td>333806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>99897</td>\n",
       "      <td>218818</td>\n",
       "      <td>271229</td>\n",
       "      <td>100159</td>\n",
       "      <td>219159</td>\n",
       "      <td>271229</td>\n",
       "      <td>100408</td>\n",
       "      <td>219532</td>\n",
       "      <td>271230</td>\n",
       "      <td>100645</td>\n",
       "      <td>...</td>\n",
       "      <td>271208</td>\n",
       "      <td>98988</td>\n",
       "      <td>217647</td>\n",
       "      <td>271217</td>\n",
       "      <td>99311</td>\n",
       "      <td>218037</td>\n",
       "      <td>271223</td>\n",
       "      <td>99610</td>\n",
       "      <td>218432</td>\n",
       "      <td>271228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>8117</td>\n",
       "      <td>23740</td>\n",
       "      <td>47751</td>\n",
       "      <td>8166</td>\n",
       "      <td>23740</td>\n",
       "      <td>47751</td>\n",
       "      <td>8192</td>\n",
       "      <td>24502</td>\n",
       "      <td>47751</td>\n",
       "      <td>8249</td>\n",
       "      <td>...</td>\n",
       "      <td>47751</td>\n",
       "      <td>7919</td>\n",
       "      <td>22823</td>\n",
       "      <td>47751</td>\n",
       "      <td>7983</td>\n",
       "      <td>23122</td>\n",
       "      <td>47751</td>\n",
       "      <td>8049</td>\n",
       "      <td>23740</td>\n",
       "      <td>47751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>17568</td>\n",
       "      <td>82398</td>\n",
       "      <td>105095</td>\n",
       "      <td>17608</td>\n",
       "      <td>82920</td>\n",
       "      <td>105095</td>\n",
       "      <td>17642</td>\n",
       "      <td>83764</td>\n",
       "      <td>105095</td>\n",
       "      <td>17684</td>\n",
       "      <td>...</td>\n",
       "      <td>105095</td>\n",
       "      <td>17371</td>\n",
       "      <td>78475</td>\n",
       "      <td>105095</td>\n",
       "      <td>17433</td>\n",
       "      <td>79871</td>\n",
       "      <td>105095</td>\n",
       "      <td>17553</td>\n",
       "      <td>81593</td>\n",
       "      <td>105095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>139223</td>\n",
       "      <td>469748</td>\n",
       "      <td>703228</td>\n",
       "      <td>140287</td>\n",
       "      <td>469748</td>\n",
       "      <td>703228</td>\n",
       "      <td>141219</td>\n",
       "      <td>469748</td>\n",
       "      <td>703228</td>\n",
       "      <td>142228</td>\n",
       "      <td>...</td>\n",
       "      <td>703228</td>\n",
       "      <td>135459</td>\n",
       "      <td>469748</td>\n",
       "      <td>703228</td>\n",
       "      <td>136736</td>\n",
       "      <td>469748</td>\n",
       "      <td>703228</td>\n",
       "      <td>138004</td>\n",
       "      <td>469748</td>\n",
       "      <td>703228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter Olympics 2022</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>2101</td>\n",
       "      <td>10127</td>\n",
       "      <td>11945</td>\n",
       "      <td>2101</td>\n",
       "      <td>10130</td>\n",
       "      <td>11945</td>\n",
       "      <td>2101</td>\n",
       "      <td>10138</td>\n",
       "      <td>11945</td>\n",
       "      <td>2101</td>\n",
       "      <td>...</td>\n",
       "      <td>11945</td>\n",
       "      <td>2096</td>\n",
       "      <td>10125</td>\n",
       "      <td>11945</td>\n",
       "      <td>2097</td>\n",
       "      <td>10126</td>\n",
       "      <td>11945</td>\n",
       "      <td>2099</td>\n",
       "      <td>10126</td>\n",
       "      <td>11945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>20997</td>\n",
       "      <td>257948</td>\n",
       "      <td>334629</td>\n",
       "      <td>21230</td>\n",
       "      <td>259677</td>\n",
       "      <td>334661</td>\n",
       "      <td>21582</td>\n",
       "      <td>261221</td>\n",
       "      <td>334695</td>\n",
       "      <td>21993</td>\n",
       "      <td>...</td>\n",
       "      <td>334196</td>\n",
       "      <td>20177</td>\n",
       "      <td>243638</td>\n",
       "      <td>334294</td>\n",
       "      <td>20462</td>\n",
       "      <td>249193</td>\n",
       "      <td>334425</td>\n",
       "      <td>20725</td>\n",
       "      <td>254274</td>\n",
       "      <td>334425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>14084</td>\n",
       "      <td>214214</td>\n",
       "      <td>259981</td>\n",
       "      <td>14491</td>\n",
       "      <td>214214</td>\n",
       "      <td>259981</td>\n",
       "      <td>15265</td>\n",
       "      <td>216087</td>\n",
       "      <td>259981</td>\n",
       "      <td>15829</td>\n",
       "      <td>...</td>\n",
       "      <td>259981</td>\n",
       "      <td>13325</td>\n",
       "      <td>207548</td>\n",
       "      <td>259981</td>\n",
       "      <td>13625</td>\n",
       "      <td>211728</td>\n",
       "      <td>259981</td>\n",
       "      <td>13867</td>\n",
       "      <td>213258</td>\n",
       "      <td>259981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 1143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1/01/2021  1/01/2022  1/01/2023  1/02/2021  1/02/2022  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan               52513     158107     207616      52586     158189   \n",
       "Albania                   58316     210224     333811      58991     210885   \n",
       "Algeria                   99897     218818     271229     100159     219159   \n",
       "Andorra                    8117      23740      47751       8166      23740   \n",
       "Angola                    17568      82398     105095      17608      82920   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza       139223     469748     703228     140287     469748   \n",
       "Winter Olympics 2022          0          0        535          0          0   \n",
       "Yemen                      2101      10127      11945       2101      10130   \n",
       "Zambia                    20997     257948     334629      21230     259677   \n",
       "Zimbabwe                  14084     214214     259981      14491     214214   \n",
       "\n",
       "                      1/02/2023  1/03/2021  1/03/2022  1/03/2023  1/04/2021  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan              207627      52709     158183     207654      52909   \n",
       "Albania                  333812      59438     210885     333812      59623   \n",
       "Algeria                  271229     100408     219532     271230     100645   \n",
       "Andorra                   47751       8192      24502      47751       8249   \n",
       "Angola                   105095      17642      83764     105095      17684   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza       703228     141219     469748     703228     142228   \n",
       "Winter Olympics 2022        535          0          0        535          0   \n",
       "Yemen                     11945       2101      10138      11945       2101   \n",
       "Zambia                   334661      21582     261221     334695      21993   \n",
       "Zimbabwe                 259981      15265     216087     259981      15829   \n",
       "\n",
       "                      ...  12/28/2022  12/29/2020  12/29/2021  12/29/2022  \\\n",
       "Country_Region        ...                                                   \n",
       "Afghanistan           ...      207493       52147      158037      207511   \n",
       "Albania               ...      333776       57146      208899      333776   \n",
       "Algeria               ...      271208       98988      217647      271217   \n",
       "Andorra               ...       47751        7919       22823       47751   \n",
       "Angola                ...      105095       17371       78475      105095   \n",
       "...                   ...         ...         ...         ...         ...   \n",
       "West Bank and Gaza    ...      703228      135459      469748      703228   \n",
       "Winter Olympics 2022  ...         535           0           0         535   \n",
       "Yemen                 ...       11945        2096       10125       11945   \n",
       "Zambia                ...      334196       20177      243638      334294   \n",
       "Zimbabwe              ...      259981       13325      207548      259981   \n",
       "\n",
       "                      12/30/2020  12/30/2021  12/30/2022  12/31/2020  \\\n",
       "Country_Region                                                         \n",
       "Afghanistan                52330      158056      207550       52330   \n",
       "Albania                    57727      208899      333806       58316   \n",
       "Algeria                    99311      218037      271223       99610   \n",
       "Andorra                     7983       23122       47751        8049   \n",
       "Angola                     17433       79871      105095       17553   \n",
       "...                          ...         ...         ...         ...   \n",
       "West Bank and Gaza        136736      469748      703228      138004   \n",
       "Winter Olympics 2022           0           0         535           0   \n",
       "Yemen                       2097       10126       11945        2099   \n",
       "Zambia                     20462      249193      334425       20725   \n",
       "Zimbabwe                   13625      211728      259981       13867   \n",
       "\n",
       "                      12/31/2021  12/31/2022  \n",
       "Country_Region                                \n",
       "Afghanistan               158084      207559  \n",
       "Albania                   210224      333806  \n",
       "Algeria                   218432      271228  \n",
       "Andorra                    23740       47751  \n",
       "Angola                     81593      105095  \n",
       "...                          ...         ...  \n",
       "West Bank and Gaza        469748      703228  \n",
       "Winter Olympics 2022           0         535  \n",
       "Yemen                      10126       11945  \n",
       "Zambia                    254274      334425  \n",
       "Zimbabwe                  213258      259981  \n",
       "\n",
       "[201 rows x 1143 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = doc.astype('int64')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8208f22",
   "metadata": {},
   "source": [
    "#### pandas 라이브러리로 csv 파일 생성\n",
    "- pandas dataframe 데이터를 csv 파일로 저장하기 위해, to_csv() 함수 사용<br>\n",
    "    doc.to_csv(\"00_data/students_default.csv\")<br><br>\n",
    "- encoding 옵션 사용 가능<br>\n",
    "    doc.to_csv(\"00_data/students_default.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f4cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(\"ex_datafile/COVID-19-master/final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2b7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78734d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
